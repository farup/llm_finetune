{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import deepspeed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from accelerate import Accelerator\n",
    "from peft import PeftModel, PeftConfig\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, AutoConfig\n",
    "from torch.utils.data import TensorDataset, DataLoader, Dataset\n",
    "from datasets import load_dataset, load_from_disk\n",
    "from tqdm.auto import tqdm\n",
    "import deepspeed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepspeed.utils.zero_to_fp32 import get_fp32_state_dict_from_zero_checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import LoraConfig, get_peft_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathPeftModel = \"/cluster/home/terjenf/norwAI_All/results/Checkpoints_NRK_Peft_NorMistral/checkpoint-28000\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_deep_model = \"/cluster/home/terjenf/norwAI_All/results/Checkpoints_NRK_Peft_NorMistral/checkpoint-28500/global_step28500\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing zero checkpoint '/cluster/home/terjenf/norwAI_All/results/Checkpoints_NRK_Peft_NorMistral/checkpoint-28000/global_step28000'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected checkpoint of type zero stage ZeroStageEnum.weights, world_size: 4\n",
      "Parsing checkpoint created by deepspeed==0.14.2\n",
      "Reconstructed Trainable fp32 state dict with 128 params 6815744 elements\n"
     ]
    }
   ],
   "source": [
    "lora_state_dict = get_fp32_state_dict_from_zero_checkpoint(pathPeftModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98eff5ad8c47407fa836b3cf82951305",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Some parameters are on the meta device device because they were offloaded to the cpu.\n"
     ]
    }
   ],
   "source": [
    "model_id = \"NorLLM-AI/NorMistral-7B\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id,device_map='auto',torch_dtype=torch.bfloat16)                                         \n",
    "model = AutoModelForCausalLM.from_pretrained(model_id, device_map='auto', torch_dtype=torch.bfloat16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "No adapter loaded. Please load an adapter first.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[78], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model\u001b[38;5;241m.\u001b[39mactive_adapters()\n",
      "File \u001b[0;32m~/.conda/envs/vgdebatt/lib/python3.11/site-packages/transformers/integrations/peft.py:383\u001b[0m, in \u001b[0;36mPeftAdapterMixin.active_adapters\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    380\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPEFT is not available. Please install PEFT to use this function: `pip install peft`.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    382\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_hf_peft_config_loaded:\n\u001b[0;32m--> 383\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo adapter loaded. Please load an adapter first.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    385\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpeft\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtuners\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtuners_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseTunerLayer\n\u001b[1;32m    387\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _, module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnamed_modules():\n",
      "\u001b[0;31mValueError\u001b[0m: No adapter loaded. Please load an adapter first."
     ]
    }
   ],
   "source": [
    "model.active_adapters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "ename": "SafetensorError",
     "evalue": "Error while deserializing header: InvalidHeaderDeserialization",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mSafetensorError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[79], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m PeftModel\u001b[38;5;241m.\u001b[39mfrom_pretrained(model, pathPeftModel)\n",
      "File \u001b[0;32m~/.conda/envs/vgdebatt/lib/python3.11/site-packages/peft/peft_model.py:430\u001b[0m, in \u001b[0;36mPeftModel.from_pretrained\u001b[0;34m(cls, model, model_id, adapter_name, is_trainable, config, **kwargs)\u001b[0m\n\u001b[1;32m    428\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    429\u001b[0m     model \u001b[38;5;241m=\u001b[39m MODEL_TYPE_TO_PEFT_MODEL_MAPPING[config\u001b[38;5;241m.\u001b[39mtask_type](model, config, adapter_name)\n\u001b[0;32m--> 430\u001b[0m model\u001b[38;5;241m.\u001b[39mload_adapter(model_id, adapter_name, is_trainable\u001b[38;5;241m=\u001b[39mis_trainable, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    431\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "File \u001b[0;32m~/.conda/envs/vgdebatt/lib/python3.11/site-packages/peft/peft_model.py:984\u001b[0m, in \u001b[0;36mPeftModel.load_adapter\u001b[0;34m(self, model_id, adapter_name, is_trainable, torch_device, **kwargs)\u001b[0m\n\u001b[1;32m    981\u001b[0m         peft_config\u001b[38;5;241m.\u001b[39minference_mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m is_trainable\n\u001b[1;32m    982\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_adapter(adapter_name, peft_config)\n\u001b[0;32m--> 984\u001b[0m adapters_weights \u001b[38;5;241m=\u001b[39m load_peft_weights(model_id, device\u001b[38;5;241m=\u001b[39mtorch_device, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mhf_hub_download_kwargs)\n\u001b[1;32m    986\u001b[0m \u001b[38;5;66;03m# load the weights into the model\u001b[39;00m\n\u001b[1;32m    987\u001b[0m ignore_mismatched_sizes \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore_mismatched_sizes\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/.conda/envs/vgdebatt/lib/python3.11/site-packages/peft/utils/save_and_load.py:444\u001b[0m, in \u001b[0;36mload_peft_weights\u001b[0;34m(model_id, device, **hf_hub_download_kwargs)\u001b[0m\n\u001b[1;32m    442\u001b[0m         adapters_weights \u001b[38;5;241m=\u001b[39m safe_load_file(filename, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    443\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 444\u001b[0m         adapters_weights \u001b[38;5;241m=\u001b[39m safe_load_file(filename, device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[1;32m    445\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    446\u001b[0m     adapters_weights \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(filename, map_location\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mdevice(device))\n",
      "File \u001b[0;32m~/.conda/envs/vgdebatt/lib/python3.11/site-packages/safetensors/torch.py:308\u001b[0m, in \u001b[0;36mload_file\u001b[0;34m(filename, device)\u001b[0m\n\u001b[1;32m    285\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    286\u001b[0m \u001b[38;5;124;03mLoads a safetensors file into torch format.\u001b[39;00m\n\u001b[1;32m    287\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;124;03m```\u001b[39;00m\n\u001b[1;32m    306\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    307\u001b[0m result \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m--> 308\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m safe_open(filename, framework\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m, device\u001b[38;5;241m=\u001b[39mdevice) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m    309\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m f\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m    310\u001b[0m         result[k] \u001b[38;5;241m=\u001b[39m f\u001b[38;5;241m.\u001b[39mget_tensor(k)\n",
      "\u001b[0;31mSafetensorError\u001b[0m: Error while deserializing header: InvalidHeaderDeserialization"
     ]
    }
   ],
   "source": [
    "model = PeftModel.from_pretrained(model, pathPeftModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(419, collections.OrderedDict)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_state_dict = model.state_dict()\n",
    "len(base_state_dict), type(base_state_dict), "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([67993, 4096]) model.embed_tokens.weight\n",
      "torch.Size([4096, 4096]) model.layers.0.self_attn.q_proj.base_layer.weight\n",
      "torch.Size([16, 4096]) model.layers.0.self_attn.q_proj.lora_A.default.weight\n",
      "torch.Size([4096, 16]) model.layers.0.self_attn.q_proj.lora_B.default.weight\n",
      "torch.Size([1024, 4096]) model.layers.0.self_attn.k_proj.weight\n",
      "torch.Size([1024, 4096]) model.layers.0.self_attn.v_proj.base_layer.weight\n",
      "torch.Size([16, 4096]) model.layers.0.self_attn.v_proj.lora_A.default.weight\n",
      "torch.Size([1024, 16]) model.layers.0.self_attn.v_proj.lora_B.default.weight\n",
      "torch.Size([4096, 4096]) model.layers.0.self_attn.o_proj.weight\n",
      "torch.Size([14336, 4096]) model.layers.0.mlp.gate_proj.weight\n",
      "torch.Size([14336, 4096]) model.layers.0.mlp.up_proj.weight\n",
      "torch.Size([4096, 14336]) model.layers.0.mlp.down_proj.weight\n",
      "torch.Size([4096]) model.layers.0.input_layernorm.weight\n",
      "torch.Size([4096]) model.layers.0.post_attention_layernorm.weight\n",
      "torch.Size([4096, 4096]) model.layers.1.self_attn.q_proj.base_layer.weight\n",
      "torch.Size([16, 4096]) model.layers.1.self_attn.q_proj.lora_A.default.weight\n",
      "torch.Size([4096, 16]) model.layers.1.self_attn.q_proj.lora_B.default.weight\n",
      "torch.Size([1024, 4096]) model.layers.1.self_attn.k_proj.weight\n",
      "torch.Size([1024, 4096]) model.layers.1.self_attn.v_proj.base_layer.weight\n",
      "torch.Size([16, 4096]) model.layers.1.self_attn.v_proj.lora_A.default.weight\n",
      "torch.Size([1024, 16]) model.layers.1.self_attn.v_proj.lora_B.default.weight\n",
      "torch.Size([4096, 4096]) model.layers.1.self_attn.o_proj.weight\n",
      "torch.Size([14336, 4096]) model.layers.1.mlp.gate_proj.weight\n",
      "torch.Size([14336, 4096]) model.layers.1.mlp.up_proj.weight\n",
      "torch.Size([4096, 14336]) model.layers.1.mlp.down_proj.weight\n",
      "torch.Size([4096]) model.layers.1.input_layernorm.weight\n",
      "torch.Size([4096]) model.layers.1.post_attention_layernorm.weight\n",
      "torch.Size([4096, 4096]) model.layers.2.self_attn.q_proj.base_layer.weight\n",
      "torch.Size([16, 4096]) model.layers.2.self_attn.q_proj.lora_A.default.weight\n",
      "torch.Size([4096, 16]) model.layers.2.self_attn.q_proj.lora_B.default.weight\n",
      "torch.Size([1024, 4096]) model.layers.2.self_attn.k_proj.weight\n",
      "torch.Size([1024, 4096]) model.layers.2.self_attn.v_proj.base_layer.weight\n",
      "torch.Size([16, 4096]) model.layers.2.self_attn.v_proj.lora_A.default.weight\n",
      "torch.Size([1024, 16]) model.layers.2.self_attn.v_proj.lora_B.default.weight\n",
      "torch.Size([4096, 4096]) model.layers.2.self_attn.o_proj.weight\n",
      "torch.Size([14336, 4096]) model.layers.2.mlp.gate_proj.weight\n",
      "torch.Size([14336, 4096]) model.layers.2.mlp.up_proj.weight\n",
      "torch.Size([4096, 14336]) model.layers.2.mlp.down_proj.weight\n",
      "torch.Size([4096]) model.layers.2.input_layernorm.weight\n",
      "torch.Size([4096]) model.layers.2.post_attention_layernorm.weight\n",
      "torch.Size([4096, 4096]) model.layers.3.self_attn.q_proj.base_layer.weight\n",
      "torch.Size([16, 4096]) model.layers.3.self_attn.q_proj.lora_A.default.weight\n",
      "torch.Size([4096, 16]) model.layers.3.self_attn.q_proj.lora_B.default.weight\n",
      "torch.Size([1024, 4096]) model.layers.3.self_attn.k_proj.weight\n",
      "torch.Size([1024, 4096]) model.layers.3.self_attn.v_proj.base_layer.weight\n",
      "torch.Size([16, 4096]) model.layers.3.self_attn.v_proj.lora_A.default.weight\n",
      "torch.Size([1024, 16]) model.layers.3.self_attn.v_proj.lora_B.default.weight\n",
      "torch.Size([4096, 4096]) model.layers.3.self_attn.o_proj.weight\n",
      "torch.Size([14336, 4096]) model.layers.3.mlp.gate_proj.weight\n",
      "torch.Size([14336, 4096]) model.layers.3.mlp.up_proj.weight\n",
      "torch.Size([4096, 14336]) model.layers.3.mlp.down_proj.weight\n",
      "torch.Size([4096]) model.layers.3.input_layernorm.weight\n",
      "torch.Size([4096]) model.layers.3.post_attention_layernorm.weight\n",
      "torch.Size([4096, 4096]) model.layers.4.self_attn.q_proj.base_layer.weight\n",
      "torch.Size([16, 4096]) model.layers.4.self_attn.q_proj.lora_A.default.weight\n",
      "torch.Size([4096, 16]) model.layers.4.self_attn.q_proj.lora_B.default.weight\n",
      "torch.Size([1024, 4096]) model.layers.4.self_attn.k_proj.weight\n",
      "torch.Size([1024, 4096]) model.layers.4.self_attn.v_proj.base_layer.weight\n",
      "torch.Size([16, 4096]) model.layers.4.self_attn.v_proj.lora_A.default.weight\n",
      "torch.Size([1024, 16]) model.layers.4.self_attn.v_proj.lora_B.default.weight\n",
      "torch.Size([4096, 4096]) model.layers.4.self_attn.o_proj.weight\n",
      "torch.Size([14336, 4096]) model.layers.4.mlp.gate_proj.weight\n",
      "torch.Size([14336, 4096]) model.layers.4.mlp.up_proj.weight\n",
      "torch.Size([4096, 14336]) model.layers.4.mlp.down_proj.weight\n",
      "torch.Size([4096]) model.layers.4.input_layernorm.weight\n",
      "torch.Size([4096]) model.layers.4.post_attention_layernorm.weight\n",
      "torch.Size([4096, 4096]) model.layers.5.self_attn.q_proj.base_layer.weight\n",
      "torch.Size([16, 4096]) model.layers.5.self_attn.q_proj.lora_A.default.weight\n",
      "torch.Size([4096, 16]) model.layers.5.self_attn.q_proj.lora_B.default.weight\n",
      "torch.Size([1024, 4096]) model.layers.5.self_attn.k_proj.weight\n",
      "torch.Size([1024, 4096]) model.layers.5.self_attn.v_proj.base_layer.weight\n",
      "torch.Size([16, 4096]) model.layers.5.self_attn.v_proj.lora_A.default.weight\n",
      "torch.Size([1024, 16]) model.layers.5.self_attn.v_proj.lora_B.default.weight\n",
      "torch.Size([4096, 4096]) model.layers.5.self_attn.o_proj.weight\n",
      "torch.Size([14336, 4096]) model.layers.5.mlp.gate_proj.weight\n",
      "torch.Size([14336, 4096]) model.layers.5.mlp.up_proj.weight\n",
      "torch.Size([4096, 14336]) model.layers.5.mlp.down_proj.weight\n",
      "torch.Size([4096]) model.layers.5.input_layernorm.weight\n",
      "torch.Size([4096]) model.layers.5.post_attention_layernorm.weight\n",
      "torch.Size([4096, 4096]) model.layers.6.self_attn.q_proj.base_layer.weight\n",
      "torch.Size([16, 4096]) model.layers.6.self_attn.q_proj.lora_A.default.weight\n",
      "torch.Size([4096, 16]) model.layers.6.self_attn.q_proj.lora_B.default.weight\n",
      "torch.Size([1024, 4096]) model.layers.6.self_attn.k_proj.weight\n",
      "torch.Size([1024, 4096]) model.layers.6.self_attn.v_proj.base_layer.weight\n",
      "torch.Size([16, 4096]) model.layers.6.self_attn.v_proj.lora_A.default.weight\n",
      "torch.Size([1024, 16]) model.layers.6.self_attn.v_proj.lora_B.default.weight\n",
      "torch.Size([4096, 4096]) model.layers.6.self_attn.o_proj.weight\n",
      "torch.Size([14336, 4096]) model.layers.6.mlp.gate_proj.weight\n",
      "torch.Size([14336, 4096]) model.layers.6.mlp.up_proj.weight\n",
      "torch.Size([4096, 14336]) model.layers.6.mlp.down_proj.weight\n",
      "torch.Size([4096]) model.layers.6.input_layernorm.weight\n",
      "torch.Size([4096]) model.layers.6.post_attention_layernorm.weight\n",
      "torch.Size([4096, 4096]) model.layers.7.self_attn.q_proj.base_layer.weight\n",
      "torch.Size([16, 4096]) model.layers.7.self_attn.q_proj.lora_A.default.weight\n",
      "torch.Size([4096, 16]) model.layers.7.self_attn.q_proj.lora_B.default.weight\n",
      "torch.Size([1024, 4096]) model.layers.7.self_attn.k_proj.weight\n",
      "torch.Size([1024, 4096]) model.layers.7.self_attn.v_proj.base_layer.weight\n",
      "torch.Size([16, 4096]) model.layers.7.self_attn.v_proj.lora_A.default.weight\n",
      "torch.Size([1024, 16]) model.layers.7.self_attn.v_proj.lora_B.default.weight\n",
      "torch.Size([4096, 4096]) model.layers.7.self_attn.o_proj.weight\n",
      "torch.Size([14336, 4096]) model.layers.7.mlp.gate_proj.weight\n",
      "torch.Size([14336, 4096]) model.layers.7.mlp.up_proj.weight\n",
      "torch.Size([4096, 14336]) model.layers.7.mlp.down_proj.weight\n",
      "torch.Size([4096]) model.layers.7.input_layernorm.weight\n",
      "torch.Size([4096]) model.layers.7.post_attention_layernorm.weight\n",
      "torch.Size([4096, 4096]) model.layers.8.self_attn.q_proj.base_layer.weight\n",
      "torch.Size([16, 4096]) model.layers.8.self_attn.q_proj.lora_A.default.weight\n",
      "torch.Size([4096, 16]) model.layers.8.self_attn.q_proj.lora_B.default.weight\n",
      "torch.Size([1024, 4096]) model.layers.8.self_attn.k_proj.weight\n",
      "torch.Size([1024, 4096]) model.layers.8.self_attn.v_proj.base_layer.weight\n",
      "torch.Size([16, 4096]) model.layers.8.self_attn.v_proj.lora_A.default.weight\n",
      "torch.Size([1024, 16]) model.layers.8.self_attn.v_proj.lora_B.default.weight\n",
      "torch.Size([4096, 4096]) model.layers.8.self_attn.o_proj.weight\n",
      "torch.Size([14336, 4096]) model.layers.8.mlp.gate_proj.weight\n",
      "torch.Size([14336, 4096]) model.layers.8.mlp.up_proj.weight\n",
      "torch.Size([4096, 14336]) model.layers.8.mlp.down_proj.weight\n",
      "torch.Size([4096]) model.layers.8.input_layernorm.weight\n",
      "torch.Size([4096]) model.layers.8.post_attention_layernorm.weight\n",
      "torch.Size([4096, 4096]) model.layers.9.self_attn.q_proj.base_layer.weight\n",
      "torch.Size([16, 4096]) model.layers.9.self_attn.q_proj.lora_A.default.weight\n",
      "torch.Size([4096, 16]) model.layers.9.self_attn.q_proj.lora_B.default.weight\n",
      "torch.Size([1024, 4096]) model.layers.9.self_attn.k_proj.weight\n",
      "torch.Size([1024, 4096]) model.layers.9.self_attn.v_proj.base_layer.weight\n",
      "torch.Size([16, 4096]) model.layers.9.self_attn.v_proj.lora_A.default.weight\n",
      "torch.Size([1024, 16]) model.layers.9.self_attn.v_proj.lora_B.default.weight\n",
      "torch.Size([4096, 4096]) model.layers.9.self_attn.o_proj.weight\n",
      "torch.Size([14336, 4096]) model.layers.9.mlp.gate_proj.weight\n",
      "torch.Size([14336, 4096]) model.layers.9.mlp.up_proj.weight\n",
      "torch.Size([4096, 14336]) model.layers.9.mlp.down_proj.weight\n",
      "torch.Size([4096]) model.layers.9.input_layernorm.weight\n",
      "torch.Size([4096]) model.layers.9.post_attention_layernorm.weight\n",
      "torch.Size([4096, 4096]) model.layers.10.self_attn.q_proj.base_layer.weight\n",
      "torch.Size([16, 4096]) model.layers.10.self_attn.q_proj.lora_A.default.weight\n",
      "torch.Size([4096, 16]) model.layers.10.self_attn.q_proj.lora_B.default.weight\n",
      "torch.Size([1024, 4096]) model.layers.10.self_attn.k_proj.weight\n",
      "torch.Size([1024, 4096]) model.layers.10.self_attn.v_proj.base_layer.weight\n",
      "torch.Size([16, 4096]) model.layers.10.self_attn.v_proj.lora_A.default.weight\n",
      "torch.Size([1024, 16]) model.layers.10.self_attn.v_proj.lora_B.default.weight\n",
      "torch.Size([4096, 4096]) model.layers.10.self_attn.o_proj.weight\n",
      "torch.Size([14336, 4096]) model.layers.10.mlp.gate_proj.weight\n",
      "torch.Size([14336, 4096]) model.layers.10.mlp.up_proj.weight\n",
      "torch.Size([4096, 14336]) model.layers.10.mlp.down_proj.weight\n",
      "torch.Size([4096]) model.layers.10.input_layernorm.weight\n",
      "torch.Size([4096]) model.layers.10.post_attention_layernorm.weight\n",
      "torch.Size([4096, 4096]) model.layers.11.self_attn.q_proj.base_layer.weight\n",
      "torch.Size([16, 4096]) model.layers.11.self_attn.q_proj.lora_A.default.weight\n",
      "torch.Size([4096, 16]) model.layers.11.self_attn.q_proj.lora_B.default.weight\n",
      "torch.Size([1024, 4096]) model.layers.11.self_attn.k_proj.weight\n",
      "torch.Size([1024, 4096]) model.layers.11.self_attn.v_proj.base_layer.weight\n",
      "torch.Size([16, 4096]) model.layers.11.self_attn.v_proj.lora_A.default.weight\n",
      "torch.Size([1024, 16]) model.layers.11.self_attn.v_proj.lora_B.default.weight\n",
      "torch.Size([4096, 4096]) model.layers.11.self_attn.o_proj.weight\n",
      "torch.Size([14336, 4096]) model.layers.11.mlp.gate_proj.weight\n",
      "torch.Size([14336, 4096]) model.layers.11.mlp.up_proj.weight\n",
      "torch.Size([4096, 14336]) model.layers.11.mlp.down_proj.weight\n",
      "torch.Size([4096]) model.layers.11.input_layernorm.weight\n",
      "torch.Size([4096]) model.layers.11.post_attention_layernorm.weight\n",
      "torch.Size([4096, 4096]) model.layers.12.self_attn.q_proj.base_layer.weight\n",
      "torch.Size([16, 4096]) model.layers.12.self_attn.q_proj.lora_A.default.weight\n",
      "torch.Size([4096, 16]) model.layers.12.self_attn.q_proj.lora_B.default.weight\n",
      "torch.Size([1024, 4096]) model.layers.12.self_attn.k_proj.weight\n",
      "torch.Size([1024, 4096]) model.layers.12.self_attn.v_proj.base_layer.weight\n",
      "torch.Size([16, 4096]) model.layers.12.self_attn.v_proj.lora_A.default.weight\n",
      "torch.Size([1024, 16]) model.layers.12.self_attn.v_proj.lora_B.default.weight\n",
      "torch.Size([4096, 4096]) model.layers.12.self_attn.o_proj.weight\n",
      "torch.Size([14336, 4096]) model.layers.12.mlp.gate_proj.weight\n",
      "torch.Size([14336, 4096]) model.layers.12.mlp.up_proj.weight\n",
      "torch.Size([4096, 14336]) model.layers.12.mlp.down_proj.weight\n",
      "torch.Size([4096]) model.layers.12.input_layernorm.weight\n",
      "torch.Size([4096]) model.layers.12.post_attention_layernorm.weight\n",
      "torch.Size([4096, 4096]) model.layers.13.self_attn.q_proj.base_layer.weight\n",
      "torch.Size([16, 4096]) model.layers.13.self_attn.q_proj.lora_A.default.weight\n",
      "torch.Size([4096, 16]) model.layers.13.self_attn.q_proj.lora_B.default.weight\n",
      "torch.Size([1024, 4096]) model.layers.13.self_attn.k_proj.weight\n",
      "torch.Size([1024, 4096]) model.layers.13.self_attn.v_proj.base_layer.weight\n",
      "torch.Size([16, 4096]) model.layers.13.self_attn.v_proj.lora_A.default.weight\n",
      "torch.Size([1024, 16]) model.layers.13.self_attn.v_proj.lora_B.default.weight\n",
      "torch.Size([4096, 4096]) model.layers.13.self_attn.o_proj.weight\n",
      "torch.Size([14336, 4096]) model.layers.13.mlp.gate_proj.weight\n",
      "torch.Size([14336, 4096]) model.layers.13.mlp.up_proj.weight\n",
      "torch.Size([4096, 14336]) model.layers.13.mlp.down_proj.weight\n",
      "torch.Size([4096]) model.layers.13.input_layernorm.weight\n",
      "torch.Size([4096]) model.layers.13.post_attention_layernorm.weight\n",
      "torch.Size([4096, 4096]) model.layers.14.self_attn.q_proj.base_layer.weight\n",
      "torch.Size([16, 4096]) model.layers.14.self_attn.q_proj.lora_A.default.weight\n",
      "torch.Size([4096, 16]) model.layers.14.self_attn.q_proj.lora_B.default.weight\n",
      "torch.Size([1024, 4096]) model.layers.14.self_attn.k_proj.weight\n",
      "torch.Size([1024, 4096]) model.layers.14.self_attn.v_proj.base_layer.weight\n",
      "torch.Size([16, 4096]) model.layers.14.self_attn.v_proj.lora_A.default.weight\n",
      "torch.Size([1024, 16]) model.layers.14.self_attn.v_proj.lora_B.default.weight\n",
      "torch.Size([4096, 4096]) model.layers.14.self_attn.o_proj.weight\n",
      "torch.Size([14336, 4096]) model.layers.14.mlp.gate_proj.weight\n",
      "torch.Size([14336, 4096]) model.layers.14.mlp.up_proj.weight\n",
      "torch.Size([4096, 14336]) model.layers.14.mlp.down_proj.weight\n",
      "torch.Size([4096]) model.layers.14.input_layernorm.weight\n",
      "torch.Size([4096]) model.layers.14.post_attention_layernorm.weight\n",
      "torch.Size([4096, 4096]) model.layers.15.self_attn.q_proj.base_layer.weight\n",
      "torch.Size([16, 4096]) model.layers.15.self_attn.q_proj.lora_A.default.weight\n",
      "torch.Size([4096, 16]) model.layers.15.self_attn.q_proj.lora_B.default.weight\n",
      "torch.Size([1024, 4096]) model.layers.15.self_attn.k_proj.weight\n",
      "torch.Size([1024, 4096]) model.layers.15.self_attn.v_proj.base_layer.weight\n",
      "torch.Size([16, 4096]) model.layers.15.self_attn.v_proj.lora_A.default.weight\n",
      "torch.Size([1024, 16]) model.layers.15.self_attn.v_proj.lora_B.default.weight\n",
      "torch.Size([4096, 4096]) model.layers.15.self_attn.o_proj.weight\n",
      "torch.Size([14336, 4096]) model.layers.15.mlp.gate_proj.weight\n",
      "torch.Size([14336, 4096]) model.layers.15.mlp.up_proj.weight\n",
      "torch.Size([4096, 14336]) model.layers.15.mlp.down_proj.weight\n",
      "torch.Size([4096]) model.layers.15.input_layernorm.weight\n",
      "torch.Size([4096]) model.layers.15.post_attention_layernorm.weight\n",
      "torch.Size([4096, 4096]) model.layers.16.self_attn.q_proj.base_layer.weight\n",
      "torch.Size([16, 4096]) model.layers.16.self_attn.q_proj.lora_A.default.weight\n",
      "torch.Size([4096, 16]) model.layers.16.self_attn.q_proj.lora_B.default.weight\n",
      "torch.Size([1024, 4096]) model.layers.16.self_attn.k_proj.weight\n",
      "torch.Size([1024, 4096]) model.layers.16.self_attn.v_proj.base_layer.weight\n",
      "torch.Size([16, 4096]) model.layers.16.self_attn.v_proj.lora_A.default.weight\n",
      "torch.Size([1024, 16]) model.layers.16.self_attn.v_proj.lora_B.default.weight\n",
      "torch.Size([4096, 4096]) model.layers.16.self_attn.o_proj.weight\n",
      "torch.Size([14336, 4096]) model.layers.16.mlp.gate_proj.weight\n",
      "torch.Size([14336, 4096]) model.layers.16.mlp.up_proj.weight\n",
      "torch.Size([4096, 14336]) model.layers.16.mlp.down_proj.weight\n",
      "torch.Size([4096]) model.layers.16.input_layernorm.weight\n",
      "torch.Size([4096]) model.layers.16.post_attention_layernorm.weight\n",
      "torch.Size([4096, 4096]) model.layers.17.self_attn.q_proj.base_layer.weight\n",
      "torch.Size([16, 4096]) model.layers.17.self_attn.q_proj.lora_A.default.weight\n",
      "torch.Size([4096, 16]) model.layers.17.self_attn.q_proj.lora_B.default.weight\n",
      "torch.Size([1024, 4096]) model.layers.17.self_attn.k_proj.weight\n",
      "torch.Size([1024, 4096]) model.layers.17.self_attn.v_proj.base_layer.weight\n",
      "torch.Size([16, 4096]) model.layers.17.self_attn.v_proj.lora_A.default.weight\n",
      "torch.Size([1024, 16]) model.layers.17.self_attn.v_proj.lora_B.default.weight\n",
      "torch.Size([4096, 4096]) model.layers.17.self_attn.o_proj.weight\n",
      "torch.Size([14336, 4096]) model.layers.17.mlp.gate_proj.weight\n",
      "torch.Size([14336, 4096]) model.layers.17.mlp.up_proj.weight\n",
      "torch.Size([4096, 14336]) model.layers.17.mlp.down_proj.weight\n",
      "torch.Size([4096]) model.layers.17.input_layernorm.weight\n",
      "torch.Size([4096]) model.layers.17.post_attention_layernorm.weight\n",
      "torch.Size([4096, 4096]) model.layers.18.self_attn.q_proj.base_layer.weight\n",
      "torch.Size([16, 4096]) model.layers.18.self_attn.q_proj.lora_A.default.weight\n",
      "torch.Size([4096, 16]) model.layers.18.self_attn.q_proj.lora_B.default.weight\n",
      "torch.Size([1024, 4096]) model.layers.18.self_attn.k_proj.weight\n",
      "torch.Size([1024, 4096]) model.layers.18.self_attn.v_proj.base_layer.weight\n",
      "torch.Size([16, 4096]) model.layers.18.self_attn.v_proj.lora_A.default.weight\n",
      "torch.Size([1024, 16]) model.layers.18.self_attn.v_proj.lora_B.default.weight\n",
      "torch.Size([4096, 4096]) model.layers.18.self_attn.o_proj.weight\n",
      "torch.Size([14336, 4096]) model.layers.18.mlp.gate_proj.weight\n",
      "torch.Size([14336, 4096]) model.layers.18.mlp.up_proj.weight\n",
      "torch.Size([4096, 14336]) model.layers.18.mlp.down_proj.weight\n",
      "torch.Size([4096]) model.layers.18.input_layernorm.weight\n",
      "torch.Size([4096]) model.layers.18.post_attention_layernorm.weight\n",
      "torch.Size([4096, 4096]) model.layers.19.self_attn.q_proj.base_layer.weight\n",
      "torch.Size([16, 4096]) model.layers.19.self_attn.q_proj.lora_A.default.weight\n",
      "torch.Size([4096, 16]) model.layers.19.self_attn.q_proj.lora_B.default.weight\n",
      "torch.Size([1024, 4096]) model.layers.19.self_attn.k_proj.weight\n",
      "torch.Size([1024, 4096]) model.layers.19.self_attn.v_proj.base_layer.weight\n",
      "torch.Size([16, 4096]) model.layers.19.self_attn.v_proj.lora_A.default.weight\n",
      "torch.Size([1024, 16]) model.layers.19.self_attn.v_proj.lora_B.default.weight\n",
      "torch.Size([4096, 4096]) model.layers.19.self_attn.o_proj.weight\n",
      "torch.Size([14336, 4096]) model.layers.19.mlp.gate_proj.weight\n",
      "torch.Size([14336, 4096]) model.layers.19.mlp.up_proj.weight\n",
      "torch.Size([4096, 14336]) model.layers.19.mlp.down_proj.weight\n",
      "torch.Size([4096]) model.layers.19.input_layernorm.weight\n",
      "torch.Size([4096]) model.layers.19.post_attention_layernorm.weight\n",
      "torch.Size([4096, 4096]) model.layers.20.self_attn.q_proj.base_layer.weight\n",
      "torch.Size([16, 4096]) model.layers.20.self_attn.q_proj.lora_A.default.weight\n",
      "torch.Size([4096, 16]) model.layers.20.self_attn.q_proj.lora_B.default.weight\n",
      "torch.Size([1024, 4096]) model.layers.20.self_attn.k_proj.weight\n",
      "torch.Size([1024, 4096]) model.layers.20.self_attn.v_proj.base_layer.weight\n",
      "torch.Size([16, 4096]) model.layers.20.self_attn.v_proj.lora_A.default.weight\n",
      "torch.Size([1024, 16]) model.layers.20.self_attn.v_proj.lora_B.default.weight\n",
      "torch.Size([4096, 4096]) model.layers.20.self_attn.o_proj.weight\n",
      "torch.Size([14336, 4096]) model.layers.20.mlp.gate_proj.weight\n",
      "torch.Size([14336, 4096]) model.layers.20.mlp.up_proj.weight\n",
      "torch.Size([4096, 14336]) model.layers.20.mlp.down_proj.weight\n",
      "torch.Size([4096]) model.layers.20.input_layernorm.weight\n",
      "torch.Size([4096]) model.layers.20.post_attention_layernorm.weight\n",
      "torch.Size([4096, 4096]) model.layers.21.self_attn.q_proj.base_layer.weight\n",
      "torch.Size([16, 4096]) model.layers.21.self_attn.q_proj.lora_A.default.weight\n",
      "torch.Size([4096, 16]) model.layers.21.self_attn.q_proj.lora_B.default.weight\n",
      "torch.Size([1024, 4096]) model.layers.21.self_attn.k_proj.weight\n",
      "torch.Size([1024, 4096]) model.layers.21.self_attn.v_proj.base_layer.weight\n",
      "torch.Size([16, 4096]) model.layers.21.self_attn.v_proj.lora_A.default.weight\n",
      "torch.Size([1024, 16]) model.layers.21.self_attn.v_proj.lora_B.default.weight\n",
      "torch.Size([4096, 4096]) model.layers.21.self_attn.o_proj.weight\n",
      "torch.Size([14336, 4096]) model.layers.21.mlp.gate_proj.weight\n",
      "torch.Size([14336, 4096]) model.layers.21.mlp.up_proj.weight\n",
      "torch.Size([4096, 14336]) model.layers.21.mlp.down_proj.weight\n",
      "torch.Size([4096]) model.layers.21.input_layernorm.weight\n",
      "torch.Size([4096]) model.layers.21.post_attention_layernorm.weight\n",
      "torch.Size([4096, 4096]) model.layers.22.self_attn.q_proj.base_layer.weight\n",
      "torch.Size([16, 4096]) model.layers.22.self_attn.q_proj.lora_A.default.weight\n",
      "torch.Size([4096, 16]) model.layers.22.self_attn.q_proj.lora_B.default.weight\n",
      "torch.Size([1024, 4096]) model.layers.22.self_attn.k_proj.weight\n",
      "torch.Size([1024, 4096]) model.layers.22.self_attn.v_proj.base_layer.weight\n",
      "torch.Size([16, 4096]) model.layers.22.self_attn.v_proj.lora_A.default.weight\n",
      "torch.Size([1024, 16]) model.layers.22.self_attn.v_proj.lora_B.default.weight\n",
      "torch.Size([4096, 4096]) model.layers.22.self_attn.o_proj.weight\n",
      "torch.Size([14336, 4096]) model.layers.22.mlp.gate_proj.weight\n",
      "torch.Size([14336, 4096]) model.layers.22.mlp.up_proj.weight\n",
      "torch.Size([4096, 14336]) model.layers.22.mlp.down_proj.weight\n",
      "torch.Size([4096]) model.layers.22.input_layernorm.weight\n",
      "torch.Size([4096]) model.layers.22.post_attention_layernorm.weight\n",
      "torch.Size([4096, 4096]) model.layers.23.self_attn.q_proj.base_layer.weight\n",
      "torch.Size([16, 4096]) model.layers.23.self_attn.q_proj.lora_A.default.weight\n",
      "torch.Size([4096, 16]) model.layers.23.self_attn.q_proj.lora_B.default.weight\n",
      "torch.Size([1024, 4096]) model.layers.23.self_attn.k_proj.weight\n",
      "torch.Size([1024, 4096]) model.layers.23.self_attn.v_proj.base_layer.weight\n",
      "torch.Size([16, 4096]) model.layers.23.self_attn.v_proj.lora_A.default.weight\n",
      "torch.Size([1024, 16]) model.layers.23.self_attn.v_proj.lora_B.default.weight\n",
      "torch.Size([4096, 4096]) model.layers.23.self_attn.o_proj.weight\n",
      "torch.Size([14336, 4096]) model.layers.23.mlp.gate_proj.weight\n",
      "torch.Size([14336, 4096]) model.layers.23.mlp.up_proj.weight\n",
      "torch.Size([4096, 14336]) model.layers.23.mlp.down_proj.weight\n",
      "torch.Size([4096]) model.layers.23.input_layernorm.weight\n",
      "torch.Size([4096]) model.layers.23.post_attention_layernorm.weight\n",
      "torch.Size([4096, 4096]) model.layers.24.self_attn.q_proj.base_layer.weight\n",
      "torch.Size([16, 4096]) model.layers.24.self_attn.q_proj.lora_A.default.weight\n",
      "torch.Size([4096, 16]) model.layers.24.self_attn.q_proj.lora_B.default.weight\n",
      "torch.Size([1024, 4096]) model.layers.24.self_attn.k_proj.weight\n",
      "torch.Size([1024, 4096]) model.layers.24.self_attn.v_proj.base_layer.weight\n",
      "torch.Size([16, 4096]) model.layers.24.self_attn.v_proj.lora_A.default.weight\n",
      "torch.Size([1024, 16]) model.layers.24.self_attn.v_proj.lora_B.default.weight\n",
      "torch.Size([4096, 4096]) model.layers.24.self_attn.o_proj.weight\n",
      "torch.Size([14336, 4096]) model.layers.24.mlp.gate_proj.weight\n",
      "torch.Size([14336, 4096]) model.layers.24.mlp.up_proj.weight\n",
      "torch.Size([4096, 14336]) model.layers.24.mlp.down_proj.weight\n",
      "torch.Size([4096]) model.layers.24.input_layernorm.weight\n",
      "torch.Size([4096]) model.layers.24.post_attention_layernorm.weight\n",
      "torch.Size([4096, 4096]) model.layers.25.self_attn.q_proj.base_layer.weight\n",
      "torch.Size([16, 4096]) model.layers.25.self_attn.q_proj.lora_A.default.weight\n",
      "torch.Size([4096, 16]) model.layers.25.self_attn.q_proj.lora_B.default.weight\n",
      "torch.Size([1024, 4096]) model.layers.25.self_attn.k_proj.weight\n",
      "torch.Size([1024, 4096]) model.layers.25.self_attn.v_proj.base_layer.weight\n",
      "torch.Size([16, 4096]) model.layers.25.self_attn.v_proj.lora_A.default.weight\n",
      "torch.Size([1024, 16]) model.layers.25.self_attn.v_proj.lora_B.default.weight\n",
      "torch.Size([4096, 4096]) model.layers.25.self_attn.o_proj.weight\n",
      "torch.Size([14336, 4096]) model.layers.25.mlp.gate_proj.weight\n",
      "torch.Size([14336, 4096]) model.layers.25.mlp.up_proj.weight\n",
      "torch.Size([4096, 14336]) model.layers.25.mlp.down_proj.weight\n",
      "torch.Size([4096]) model.layers.25.input_layernorm.weight\n",
      "torch.Size([4096]) model.layers.25.post_attention_layernorm.weight\n",
      "torch.Size([4096, 4096]) model.layers.26.self_attn.q_proj.base_layer.weight\n",
      "torch.Size([16, 4096]) model.layers.26.self_attn.q_proj.lora_A.default.weight\n",
      "torch.Size([4096, 16]) model.layers.26.self_attn.q_proj.lora_B.default.weight\n",
      "torch.Size([1024, 4096]) model.layers.26.self_attn.k_proj.weight\n",
      "torch.Size([1024, 4096]) model.layers.26.self_attn.v_proj.base_layer.weight\n",
      "torch.Size([16, 4096]) model.layers.26.self_attn.v_proj.lora_A.default.weight\n",
      "torch.Size([1024, 16]) model.layers.26.self_attn.v_proj.lora_B.default.weight\n",
      "torch.Size([4096, 4096]) model.layers.26.self_attn.o_proj.weight\n",
      "torch.Size([14336, 4096]) model.layers.26.mlp.gate_proj.weight\n",
      "torch.Size([14336, 4096]) model.layers.26.mlp.up_proj.weight\n",
      "torch.Size([4096, 14336]) model.layers.26.mlp.down_proj.weight\n",
      "torch.Size([4096]) model.layers.26.input_layernorm.weight\n",
      "torch.Size([4096]) model.layers.26.post_attention_layernorm.weight\n",
      "torch.Size([4096, 4096]) model.layers.27.self_attn.q_proj.base_layer.weight\n",
      "torch.Size([16, 4096]) model.layers.27.self_attn.q_proj.lora_A.default.weight\n",
      "torch.Size([4096, 16]) model.layers.27.self_attn.q_proj.lora_B.default.weight\n",
      "torch.Size([1024, 4096]) model.layers.27.self_attn.k_proj.weight\n",
      "torch.Size([1024, 4096]) model.layers.27.self_attn.v_proj.base_layer.weight\n",
      "torch.Size([16, 4096]) model.layers.27.self_attn.v_proj.lora_A.default.weight\n",
      "torch.Size([1024, 16]) model.layers.27.self_attn.v_proj.lora_B.default.weight\n",
      "torch.Size([4096, 4096]) model.layers.27.self_attn.o_proj.weight\n",
      "torch.Size([14336, 4096]) model.layers.27.mlp.gate_proj.weight\n",
      "torch.Size([14336, 4096]) model.layers.27.mlp.up_proj.weight\n",
      "torch.Size([4096, 14336]) model.layers.27.mlp.down_proj.weight\n",
      "torch.Size([4096]) model.layers.27.input_layernorm.weight\n",
      "torch.Size([4096]) model.layers.27.post_attention_layernorm.weight\n",
      "torch.Size([4096, 4096]) model.layers.28.self_attn.q_proj.base_layer.weight\n",
      "torch.Size([16, 4096]) model.layers.28.self_attn.q_proj.lora_A.default.weight\n",
      "torch.Size([4096, 16]) model.layers.28.self_attn.q_proj.lora_B.default.weight\n",
      "torch.Size([1024, 4096]) model.layers.28.self_attn.k_proj.weight\n",
      "torch.Size([1024, 4096]) model.layers.28.self_attn.v_proj.base_layer.weight\n",
      "torch.Size([16, 4096]) model.layers.28.self_attn.v_proj.lora_A.default.weight\n",
      "torch.Size([1024, 16]) model.layers.28.self_attn.v_proj.lora_B.default.weight\n",
      "torch.Size([4096, 4096]) model.layers.28.self_attn.o_proj.weight\n",
      "torch.Size([14336, 4096]) model.layers.28.mlp.gate_proj.weight\n",
      "torch.Size([14336, 4096]) model.layers.28.mlp.up_proj.weight\n",
      "torch.Size([4096, 14336]) model.layers.28.mlp.down_proj.weight\n",
      "torch.Size([4096]) model.layers.28.input_layernorm.weight\n",
      "torch.Size([4096]) model.layers.28.post_attention_layernorm.weight\n",
      "torch.Size([4096, 4096]) model.layers.29.self_attn.q_proj.base_layer.weight\n",
      "torch.Size([16, 4096]) model.layers.29.self_attn.q_proj.lora_A.default.weight\n",
      "torch.Size([4096, 16]) model.layers.29.self_attn.q_proj.lora_B.default.weight\n",
      "torch.Size([1024, 4096]) model.layers.29.self_attn.k_proj.weight\n",
      "torch.Size([1024, 4096]) model.layers.29.self_attn.v_proj.base_layer.weight\n",
      "torch.Size([16, 4096]) model.layers.29.self_attn.v_proj.lora_A.default.weight\n",
      "torch.Size([1024, 16]) model.layers.29.self_attn.v_proj.lora_B.default.weight\n",
      "torch.Size([4096, 4096]) model.layers.29.self_attn.o_proj.weight\n",
      "torch.Size([14336, 4096]) model.layers.29.mlp.gate_proj.weight\n",
      "torch.Size([14336, 4096]) model.layers.29.mlp.up_proj.weight\n",
      "torch.Size([4096, 14336]) model.layers.29.mlp.down_proj.weight\n",
      "torch.Size([4096]) model.layers.29.input_layernorm.weight\n",
      "torch.Size([4096]) model.layers.29.post_attention_layernorm.weight\n",
      "torch.Size([4096, 4096]) model.layers.30.self_attn.q_proj.base_layer.weight\n",
      "torch.Size([16, 4096]) model.layers.30.self_attn.q_proj.lora_A.default.weight\n",
      "torch.Size([4096, 16]) model.layers.30.self_attn.q_proj.lora_B.default.weight\n",
      "torch.Size([1024, 4096]) model.layers.30.self_attn.k_proj.weight\n",
      "torch.Size([1024, 4096]) model.layers.30.self_attn.v_proj.base_layer.weight\n",
      "torch.Size([16, 4096]) model.layers.30.self_attn.v_proj.lora_A.default.weight\n",
      "torch.Size([1024, 16]) model.layers.30.self_attn.v_proj.lora_B.default.weight\n",
      "torch.Size([4096, 4096]) model.layers.30.self_attn.o_proj.weight\n",
      "torch.Size([14336, 4096]) model.layers.30.mlp.gate_proj.weight\n",
      "torch.Size([14336, 4096]) model.layers.30.mlp.up_proj.weight\n",
      "torch.Size([4096, 14336]) model.layers.30.mlp.down_proj.weight\n",
      "torch.Size([4096]) model.layers.30.input_layernorm.weight\n",
      "torch.Size([4096]) model.layers.30.post_attention_layernorm.weight\n",
      "torch.Size([4096, 4096]) model.layers.31.self_attn.q_proj.base_layer.weight\n",
      "torch.Size([16, 4096]) model.layers.31.self_attn.q_proj.lora_A.default.weight\n",
      "torch.Size([4096, 16]) model.layers.31.self_attn.q_proj.lora_B.default.weight\n",
      "torch.Size([1024, 4096]) model.layers.31.self_attn.k_proj.weight\n",
      "torch.Size([1024, 4096]) model.layers.31.self_attn.v_proj.base_layer.weight\n",
      "torch.Size([16, 4096]) model.layers.31.self_attn.v_proj.lora_A.default.weight\n",
      "torch.Size([1024, 16]) model.layers.31.self_attn.v_proj.lora_B.default.weight\n",
      "torch.Size([4096, 4096]) model.layers.31.self_attn.o_proj.weight\n",
      "torch.Size([14336, 4096]) model.layers.31.mlp.gate_proj.weight\n",
      "torch.Size([14336, 4096]) model.layers.31.mlp.up_proj.weight\n",
      "torch.Size([4096, 14336]) model.layers.31.mlp.down_proj.weight\n",
      "torch.Size([4096]) model.layers.31.input_layernorm.weight\n",
      "torch.Size([4096]) model.layers.31.post_attention_layernorm.weight\n",
      "torch.Size([4096]) model.norm.weight\n",
      "torch.Size([67993, 4096]) lm_head.weight\n"
     ]
    }
   ],
   "source": [
    "for state in base_state_dict.keys():\n",
    "    print(base_state_dict.get(state).shape, state)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "No adapter loaded. Please load an adapter first.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[82], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m sata \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mget_adapter_state_dict()\n",
      "File \u001b[0;32m~/.conda/envs/vgdebatt/lib/python3.11/site-packages/transformers/integrations/peft.py:420\u001b[0m, in \u001b[0;36mPeftAdapterMixin.get_adapter_state_dict\u001b[0;34m(self, adapter_name)\u001b[0m\n\u001b[1;32m    417\u001b[0m check_peft_version(min_version\u001b[38;5;241m=\u001b[39mMIN_PEFT_VERSION)\n\u001b[1;32m    419\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_hf_peft_config_loaded:\n\u001b[0;32m--> 420\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo adapter loaded. Please load an adapter first.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    422\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpeft\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_peft_model_state_dict\n\u001b[1;32m    424\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m adapter_name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mValueError\u001b[0m: No adapter loaded. Please load an adapter first."
     ]
    }
   ],
   "source": [
    "sata = model.get_adapter_state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_adapter(pathPeftModel, \"zero3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['zero3']"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.active_adapters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.set_adapter(\"zero3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_state_dict = model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.embed_tokens.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.0.self_attn.q_proj.base_layer.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.0.self_attn.q_proj.lora_A.default.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.0.self_attn.q_proj.lora_A.zero3.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.0.self_attn.q_proj.lora_B.default.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.0.self_attn.q_proj.lora_B.zero3.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.0.self_attn.k_proj.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.0.self_attn.v_proj.base_layer.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.0.self_attn.v_proj.lora_A.default.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.0.self_attn.v_proj.lora_A.zero3.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.0.self_attn.v_proj.lora_B.default.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.0.self_attn.v_proj.lora_B.zero3.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.0.self_attn.o_proj.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.0.mlp.gate_proj.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.0.mlp.up_proj.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.0.mlp.down_proj.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.0.input_layernorm.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.0.post_attention_layernorm.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.1.self_attn.q_proj.base_layer.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.1.self_attn.q_proj.lora_A.default.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.1.self_attn.q_proj.lora_A.zero3.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.1.self_attn.q_proj.lora_B.default.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.1.self_attn.q_proj.lora_B.zero3.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.1.self_attn.k_proj.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.1.self_attn.v_proj.base_layer.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.1.self_attn.v_proj.lora_A.default.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.1.self_attn.v_proj.lora_A.zero3.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.1.self_attn.v_proj.lora_B.default.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.1.self_attn.v_proj.lora_B.zero3.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.1.self_attn.o_proj.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.1.mlp.gate_proj.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.1.mlp.up_proj.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.1.mlp.down_proj.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.1.input_layernorm.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.1.post_attention_layernorm.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.2.self_attn.q_proj.base_layer.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.2.self_attn.q_proj.lora_A.default.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.2.self_attn.q_proj.lora_A.zero3.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.2.self_attn.q_proj.lora_B.default.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.2.self_attn.q_proj.lora_B.zero3.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.2.self_attn.k_proj.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.2.self_attn.v_proj.base_layer.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.2.self_attn.v_proj.lora_A.default.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.2.self_attn.v_proj.lora_A.zero3.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.2.self_attn.v_proj.lora_B.default.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.2.self_attn.v_proj.lora_B.zero3.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.2.self_attn.o_proj.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.2.mlp.gate_proj.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.2.mlp.up_proj.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.2.mlp.down_proj.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.2.input_layernorm.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.2.post_attention_layernorm.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.3.self_attn.q_proj.base_layer.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.3.self_attn.q_proj.lora_A.default.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.3.self_attn.q_proj.lora_A.zero3.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.3.self_attn.q_proj.lora_B.default.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.3.self_attn.q_proj.lora_B.zero3.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.3.self_attn.k_proj.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.3.self_attn.v_proj.base_layer.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.3.self_attn.v_proj.lora_A.default.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.3.self_attn.v_proj.lora_A.zero3.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.3.self_attn.v_proj.lora_B.default.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.3.self_attn.v_proj.lora_B.zero3.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.3.self_attn.o_proj.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.3.mlp.gate_proj.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.3.mlp.up_proj.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.3.mlp.down_proj.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.3.input_layernorm.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.3.post_attention_layernorm.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.4.self_attn.q_proj.base_layer.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.4.self_attn.q_proj.lora_A.default.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.4.self_attn.q_proj.lora_A.zero3.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.4.self_attn.q_proj.lora_B.default.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.4.self_attn.q_proj.lora_B.zero3.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.4.self_attn.k_proj.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.4.self_attn.v_proj.base_layer.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.4.self_attn.v_proj.lora_A.default.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.4.self_attn.v_proj.lora_A.zero3.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.4.self_attn.v_proj.lora_B.default.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.4.self_attn.v_proj.lora_B.zero3.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.4.self_attn.o_proj.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.4.mlp.gate_proj.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.4.mlp.up_proj.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.4.mlp.down_proj.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.4.input_layernorm.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.4.post_attention_layernorm.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.5.self_attn.q_proj.base_layer.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.5.self_attn.q_proj.lora_A.default.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.5.self_attn.q_proj.lora_A.zero3.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.5.self_attn.q_proj.lora_B.default.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.5.self_attn.q_proj.lora_B.zero3.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.5.self_attn.k_proj.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.5.self_attn.v_proj.base_layer.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.5.self_attn.v_proj.lora_A.default.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.5.self_attn.v_proj.lora_A.zero3.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.5.self_attn.v_proj.lora_B.default.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.5.self_attn.v_proj.lora_B.zero3.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.5.self_attn.o_proj.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.5.mlp.gate_proj.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.5.mlp.up_proj.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.5.mlp.down_proj.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.5.input_layernorm.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.5.post_attention_layernorm.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.6.self_attn.q_proj.base_layer.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.6.self_attn.q_proj.lora_A.default.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.6.self_attn.q_proj.lora_A.zero3.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.6.self_attn.q_proj.lora_B.default.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.6.self_attn.q_proj.lora_B.zero3.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.6.self_attn.k_proj.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.6.self_attn.v_proj.base_layer.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.6.self_attn.v_proj.lora_A.default.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.6.self_attn.v_proj.lora_A.zero3.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.6.self_attn.v_proj.lora_B.default.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.6.self_attn.v_proj.lora_B.zero3.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.6.self_attn.o_proj.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.6.mlp.gate_proj.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.6.mlp.up_proj.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.6.mlp.down_proj.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.6.input_layernorm.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.6.post_attention_layernorm.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.7.self_attn.q_proj.base_layer.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.7.self_attn.q_proj.lora_A.default.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.7.self_attn.q_proj.lora_A.zero3.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.7.self_attn.q_proj.lora_B.default.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.7.self_attn.q_proj.lora_B.zero3.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.7.self_attn.k_proj.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.7.self_attn.v_proj.base_layer.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.7.self_attn.v_proj.lora_A.default.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.7.self_attn.v_proj.lora_A.zero3.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.7.self_attn.v_proj.lora_B.default.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.7.self_attn.v_proj.lora_B.zero3.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.7.self_attn.o_proj.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.7.mlp.gate_proj.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.7.mlp.up_proj.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.7.mlp.down_proj.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.7.input_layernorm.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.7.post_attention_layernorm.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.8.self_attn.q_proj.base_layer.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.8.self_attn.q_proj.lora_A.default.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.8.self_attn.q_proj.lora_A.zero3.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.8.self_attn.q_proj.lora_B.default.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.8.self_attn.q_proj.lora_B.zero3.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.8.self_attn.k_proj.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.8.self_attn.v_proj.base_layer.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.8.self_attn.v_proj.lora_A.default.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.8.self_attn.v_proj.lora_A.zero3.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.8.self_attn.v_proj.lora_B.default.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.8.self_attn.v_proj.lora_B.zero3.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.8.self_attn.o_proj.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.8.mlp.gate_proj.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.8.mlp.up_proj.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.8.mlp.down_proj.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.8.input_layernorm.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.8.post_attention_layernorm.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.9.self_attn.q_proj.base_layer.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.9.self_attn.q_proj.lora_A.default.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.9.self_attn.q_proj.lora_A.zero3.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.9.self_attn.q_proj.lora_B.default.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.9.self_attn.q_proj.lora_B.zero3.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.9.self_attn.k_proj.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.9.self_attn.v_proj.base_layer.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.9.self_attn.v_proj.lora_A.default.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.9.self_attn.v_proj.lora_A.zero3.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.9.self_attn.v_proj.lora_B.default.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.9.self_attn.v_proj.lora_B.zero3.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.9.self_attn.o_proj.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.9.mlp.gate_proj.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.9.mlp.up_proj.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.9.mlp.down_proj.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.9.input_layernorm.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.9.post_attention_layernorm.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.10.self_attn.q_proj.base_layer.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.10.self_attn.q_proj.lora_A.default.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.10.self_attn.q_proj.lora_A.zero3.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.10.self_attn.q_proj.lora_B.default.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.10.self_attn.q_proj.lora_B.zero3.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.10.self_attn.k_proj.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.10.self_attn.v_proj.base_layer.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.10.self_attn.v_proj.lora_A.default.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.10.self_attn.v_proj.lora_A.zero3.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.10.self_attn.v_proj.lora_B.default.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.10.self_attn.v_proj.lora_B.zero3.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.10.self_attn.o_proj.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.10.mlp.gate_proj.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.10.mlp.up_proj.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.10.mlp.down_proj.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.10.input_layernorm.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.10.post_attention_layernorm.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.11.self_attn.q_proj.base_layer.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.11.self_attn.q_proj.lora_A.default.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.11.self_attn.q_proj.lora_A.zero3.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.11.self_attn.q_proj.lora_B.default.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.11.self_attn.q_proj.lora_B.zero3.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.11.self_attn.k_proj.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.11.self_attn.v_proj.base_layer.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.11.self_attn.v_proj.lora_A.default.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.11.self_attn.v_proj.lora_A.zero3.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.11.self_attn.v_proj.lora_B.default.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.11.self_attn.v_proj.lora_B.zero3.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.11.self_attn.o_proj.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.11.mlp.gate_proj.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.11.mlp.up_proj.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.11.mlp.down_proj.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.11.input_layernorm.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.11.post_attention_layernorm.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.12.self_attn.q_proj.base_layer.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.12.self_attn.q_proj.lora_A.default.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.12.self_attn.q_proj.lora_A.zero3.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.12.self_attn.q_proj.lora_B.default.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.12.self_attn.q_proj.lora_B.zero3.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.12.self_attn.k_proj.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.12.self_attn.v_proj.base_layer.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.12.self_attn.v_proj.lora_A.default.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.12.self_attn.v_proj.lora_A.zero3.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.12.self_attn.v_proj.lora_B.default.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.12.self_attn.v_proj.lora_B.zero3.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.12.self_attn.o_proj.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.12.mlp.gate_proj.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.12.mlp.up_proj.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.12.mlp.down_proj.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.12.input_layernorm.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.12.post_attention_layernorm.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.13.self_attn.q_proj.base_layer.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.13.self_attn.q_proj.lora_A.default.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.13.self_attn.q_proj.lora_A.zero3.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.13.self_attn.q_proj.lora_B.default.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.13.self_attn.q_proj.lora_B.zero3.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.13.self_attn.k_proj.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.13.self_attn.v_proj.base_layer.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.13.self_attn.v_proj.lora_A.default.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.13.self_attn.v_proj.lora_A.zero3.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.13.self_attn.v_proj.lora_B.default.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.13.self_attn.v_proj.lora_B.zero3.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.13.self_attn.o_proj.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.13.mlp.gate_proj.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.13.mlp.up_proj.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.13.mlp.down_proj.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.13.input_layernorm.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.13.post_attention_layernorm.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.14.self_attn.q_proj.base_layer.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.14.self_attn.q_proj.lora_A.default.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.14.self_attn.q_proj.lora_A.zero3.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.14.self_attn.q_proj.lora_B.default.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.14.self_attn.q_proj.lora_B.zero3.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.14.self_attn.k_proj.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.14.self_attn.v_proj.base_layer.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.14.self_attn.v_proj.lora_A.default.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.14.self_attn.v_proj.lora_A.zero3.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.14.self_attn.v_proj.lora_B.default.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.14.self_attn.v_proj.lora_B.zero3.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.14.self_attn.o_proj.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.14.mlp.gate_proj.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.14.mlp.up_proj.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.14.mlp.down_proj.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.14.input_layernorm.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.14.post_attention_layernorm.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.15.self_attn.q_proj.base_layer.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.15.self_attn.q_proj.lora_A.default.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.15.self_attn.q_proj.lora_A.zero3.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.15.self_attn.q_proj.lora_B.default.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.15.self_attn.q_proj.lora_B.zero3.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.15.self_attn.k_proj.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.15.self_attn.v_proj.base_layer.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.15.self_attn.v_proj.lora_A.default.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.15.self_attn.v_proj.lora_A.zero3.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.15.self_attn.v_proj.lora_B.default.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.15.self_attn.v_proj.lora_B.zero3.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.15.self_attn.o_proj.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.15.mlp.gate_proj.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.15.mlp.up_proj.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.15.mlp.down_proj.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.15.input_layernorm.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.15.post_attention_layernorm.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.16.self_attn.q_proj.base_layer.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.16.self_attn.q_proj.lora_A.default.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.16.self_attn.q_proj.lora_A.zero3.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.16.self_attn.q_proj.lora_B.default.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.16.self_attn.q_proj.lora_B.zero3.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.16.self_attn.k_proj.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.16.self_attn.v_proj.base_layer.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.16.self_attn.v_proj.lora_A.default.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.16.self_attn.v_proj.lora_A.zero3.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.16.self_attn.v_proj.lora_B.default.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.16.self_attn.v_proj.lora_B.zero3.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.16.self_attn.o_proj.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.16.mlp.gate_proj.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.16.mlp.up_proj.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.16.mlp.down_proj.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.16.input_layernorm.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.16.post_attention_layernorm.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.17.self_attn.q_proj.base_layer.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.17.self_attn.q_proj.lora_A.default.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.17.self_attn.q_proj.lora_A.zero3.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.17.self_attn.q_proj.lora_B.default.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.17.self_attn.q_proj.lora_B.zero3.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.17.self_attn.k_proj.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.17.self_attn.v_proj.base_layer.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.17.self_attn.v_proj.lora_A.default.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.17.self_attn.v_proj.lora_A.zero3.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.17.self_attn.v_proj.lora_B.default.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.17.self_attn.v_proj.lora_B.zero3.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.17.self_attn.o_proj.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.17.mlp.gate_proj.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.17.mlp.up_proj.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.17.mlp.down_proj.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.17.input_layernorm.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.17.post_attention_layernorm.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.18.self_attn.q_proj.base_layer.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.18.self_attn.q_proj.lora_A.default.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.18.self_attn.q_proj.lora_A.zero3.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.18.self_attn.q_proj.lora_B.default.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.18.self_attn.q_proj.lora_B.zero3.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.18.self_attn.k_proj.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.18.self_attn.v_proj.base_layer.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.18.self_attn.v_proj.lora_A.default.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.18.self_attn.v_proj.lora_A.zero3.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.18.self_attn.v_proj.lora_B.default.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.18.self_attn.v_proj.lora_B.zero3.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.18.self_attn.o_proj.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.18.mlp.gate_proj.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.18.mlp.up_proj.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.18.mlp.down_proj.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.18.input_layernorm.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.18.post_attention_layernorm.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.19.self_attn.q_proj.base_layer.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.19.self_attn.q_proj.lora_A.default.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.19.self_attn.q_proj.lora_A.zero3.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.19.self_attn.q_proj.lora_B.default.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.19.self_attn.q_proj.lora_B.zero3.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.19.self_attn.k_proj.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.19.self_attn.v_proj.base_layer.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.19.self_attn.v_proj.lora_A.default.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.19.self_attn.v_proj.lora_A.zero3.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.19.self_attn.v_proj.lora_B.default.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.19.self_attn.v_proj.lora_B.zero3.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.19.self_attn.o_proj.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.19.mlp.gate_proj.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.19.mlp.up_proj.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.19.mlp.down_proj.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.19.input_layernorm.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.19.post_attention_layernorm.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.20.self_attn.q_proj.base_layer.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.20.self_attn.q_proj.lora_A.default.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.20.self_attn.q_proj.lora_A.zero3.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.20.self_attn.q_proj.lora_B.default.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.20.self_attn.q_proj.lora_B.zero3.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.20.self_attn.k_proj.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.20.self_attn.v_proj.base_layer.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.20.self_attn.v_proj.lora_A.default.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.20.self_attn.v_proj.lora_A.zero3.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.20.self_attn.v_proj.lora_B.default.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.20.self_attn.v_proj.lora_B.zero3.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.20.self_attn.o_proj.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.20.mlp.gate_proj.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.20.mlp.up_proj.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.20.mlp.down_proj.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.20.input_layernorm.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.20.post_attention_layernorm.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.21.self_attn.q_proj.base_layer.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.21.self_attn.q_proj.lora_A.default.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.21.self_attn.q_proj.lora_A.zero3.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.21.self_attn.q_proj.lora_B.default.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.21.self_attn.q_proj.lora_B.zero3.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.21.self_attn.k_proj.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.21.self_attn.v_proj.base_layer.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.21.self_attn.v_proj.lora_A.default.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.21.self_attn.v_proj.lora_A.zero3.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.21.self_attn.v_proj.lora_B.default.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.21.self_attn.v_proj.lora_B.zero3.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.21.self_attn.o_proj.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.21.mlp.gate_proj.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.21.mlp.up_proj.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.21.mlp.down_proj.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.21.input_layernorm.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.21.post_attention_layernorm.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.22.self_attn.q_proj.base_layer.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.22.self_attn.q_proj.lora_A.default.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.22.self_attn.q_proj.lora_A.zero3.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.22.self_attn.q_proj.lora_B.default.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.22.self_attn.q_proj.lora_B.zero3.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.22.self_attn.k_proj.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.22.self_attn.v_proj.base_layer.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.22.self_attn.v_proj.lora_A.default.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.22.self_attn.v_proj.lora_A.zero3.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.22.self_attn.v_proj.lora_B.default.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.22.self_attn.v_proj.lora_B.zero3.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.22.self_attn.o_proj.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.22.mlp.gate_proj.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.22.mlp.up_proj.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.22.mlp.down_proj.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.22.input_layernorm.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.22.post_attention_layernorm.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.23.self_attn.q_proj.base_layer.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.23.self_attn.q_proj.lora_A.default.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.23.self_attn.q_proj.lora_A.zero3.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.23.self_attn.q_proj.lora_B.default.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.23.self_attn.q_proj.lora_B.zero3.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.23.self_attn.k_proj.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.23.self_attn.v_proj.base_layer.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.23.self_attn.v_proj.lora_A.default.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.23.self_attn.v_proj.lora_A.zero3.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.23.self_attn.v_proj.lora_B.default.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.23.self_attn.v_proj.lora_B.zero3.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.23.self_attn.o_proj.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.23.mlp.gate_proj.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.23.mlp.up_proj.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.23.mlp.down_proj.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.23.input_layernorm.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.23.post_attention_layernorm.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.24.self_attn.q_proj.base_layer.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.24.self_attn.q_proj.lora_A.default.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.24.self_attn.q_proj.lora_A.zero3.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.24.self_attn.q_proj.lora_B.default.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.24.self_attn.q_proj.lora_B.zero3.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.24.self_attn.k_proj.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.24.self_attn.v_proj.base_layer.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.24.self_attn.v_proj.lora_A.default.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.24.self_attn.v_proj.lora_A.zero3.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.24.self_attn.v_proj.lora_B.default.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.24.self_attn.v_proj.lora_B.zero3.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.24.self_attn.o_proj.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.24.mlp.gate_proj.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.24.mlp.up_proj.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.24.mlp.down_proj.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.24.input_layernorm.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.24.post_attention_layernorm.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.25.self_attn.q_proj.base_layer.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.25.self_attn.q_proj.lora_A.default.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.25.self_attn.q_proj.lora_A.zero3.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.25.self_attn.q_proj.lora_B.default.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.25.self_attn.q_proj.lora_B.zero3.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.25.self_attn.k_proj.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.25.self_attn.v_proj.base_layer.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.25.self_attn.v_proj.lora_A.default.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.25.self_attn.v_proj.lora_A.zero3.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.25.self_attn.v_proj.lora_B.default.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.25.self_attn.v_proj.lora_B.zero3.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.25.self_attn.o_proj.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.25.mlp.gate_proj.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.25.mlp.up_proj.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.25.mlp.down_proj.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.25.input_layernorm.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.25.post_attention_layernorm.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.26.self_attn.q_proj.base_layer.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.26.self_attn.q_proj.lora_A.default.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.26.self_attn.q_proj.lora_A.zero3.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.26.self_attn.q_proj.lora_B.default.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.26.self_attn.q_proj.lora_B.zero3.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.26.self_attn.k_proj.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.26.self_attn.v_proj.base_layer.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.26.self_attn.v_proj.lora_A.default.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.26.self_attn.v_proj.lora_A.zero3.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.26.self_attn.v_proj.lora_B.default.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.26.self_attn.v_proj.lora_B.zero3.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.26.self_attn.o_proj.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.26.mlp.gate_proj.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.26.mlp.up_proj.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.26.mlp.down_proj.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.26.input_layernorm.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.26.post_attention_layernorm.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.27.self_attn.q_proj.base_layer.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.27.self_attn.q_proj.lora_A.default.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.27.self_attn.q_proj.lora_A.zero3.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.27.self_attn.q_proj.lora_B.default.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.27.self_attn.q_proj.lora_B.zero3.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.27.self_attn.k_proj.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.27.self_attn.v_proj.base_layer.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.27.self_attn.v_proj.lora_A.default.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.27.self_attn.v_proj.lora_A.zero3.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.27.self_attn.v_proj.lora_B.default.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.27.self_attn.v_proj.lora_B.zero3.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.27.self_attn.o_proj.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.27.mlp.gate_proj.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.27.mlp.up_proj.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.27.mlp.down_proj.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.27.input_layernorm.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.27.post_attention_layernorm.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.28.self_attn.q_proj.base_layer.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.28.self_attn.q_proj.lora_A.default.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.28.self_attn.q_proj.lora_A.zero3.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.28.self_attn.q_proj.lora_B.default.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.28.self_attn.q_proj.lora_B.zero3.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.28.self_attn.k_proj.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.28.self_attn.v_proj.base_layer.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.28.self_attn.v_proj.lora_A.default.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.28.self_attn.v_proj.lora_A.zero3.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.28.self_attn.v_proj.lora_B.default.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.28.self_attn.v_proj.lora_B.zero3.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.28.self_attn.o_proj.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.28.mlp.gate_proj.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.28.mlp.up_proj.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.28.mlp.down_proj.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.28.input_layernorm.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.28.post_attention_layernorm.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.29.self_attn.q_proj.base_layer.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.29.self_attn.q_proj.lora_A.default.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.29.self_attn.q_proj.lora_A.zero3.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.29.self_attn.q_proj.lora_B.default.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.29.self_attn.q_proj.lora_B.zero3.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.29.self_attn.k_proj.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.29.self_attn.v_proj.base_layer.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.29.self_attn.v_proj.lora_A.default.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.29.self_attn.v_proj.lora_A.zero3.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.29.self_attn.v_proj.lora_B.default.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.29.self_attn.v_proj.lora_B.zero3.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.29.self_attn.o_proj.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.29.mlp.gate_proj.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.29.mlp.up_proj.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.29.mlp.down_proj.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.29.input_layernorm.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.29.post_attention_layernorm.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.30.self_attn.q_proj.base_layer.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.30.self_attn.q_proj.lora_A.default.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.30.self_attn.q_proj.lora_A.zero3.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.30.self_attn.q_proj.lora_B.default.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.30.self_attn.q_proj.lora_B.zero3.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.30.self_attn.k_proj.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.30.self_attn.v_proj.base_layer.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.30.self_attn.v_proj.lora_A.default.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.30.self_attn.v_proj.lora_A.zero3.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.30.self_attn.v_proj.lora_B.default.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.30.self_attn.v_proj.lora_B.zero3.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.30.self_attn.o_proj.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.30.mlp.gate_proj.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.30.mlp.up_proj.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.30.mlp.down_proj.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.30.input_layernorm.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.30.post_attention_layernorm.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.31.self_attn.q_proj.base_layer.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.31.self_attn.q_proj.lora_A.default.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.31.self_attn.q_proj.lora_A.zero3.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.31.self_attn.q_proj.lora_B.default.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.31.self_attn.q_proj.lora_B.zero3.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.31.self_attn.k_proj.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.31.self_attn.v_proj.base_layer.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.31.self_attn.v_proj.lora_A.default.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.31.self_attn.v_proj.lora_A.zero3.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.31.self_attn.v_proj.lora_B.default.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.31.self_attn.v_proj.lora_B.zero3.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.31.self_attn.o_proj.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.31.mlp.gate_proj.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.31.mlp.up_proj.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.31.mlp.down_proj.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.31.input_layernorm.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.layers.31.post_attention_layernorm.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "model.norm.weight\n",
      "---------Nice--------\n",
      "--------------error-------- 'NoneType' object has no attribute 'shape'\n",
      "lm_head.weight\n"
     ]
    }
   ],
   "source": [
    "for state in model_state_dict.keys():\n",
    "    try: \n",
    "        print(\"---------Nice--------\")\n",
    "        print(lora_state_dict.get(state).shape, state)\n",
    "    except Exception as error:\n",
    "        print(\"--------------error--------\", error)\n",
    "        print(\"--error-state-----------------------\"state)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cluster/home/terjenf/.conda/envs/vgdebatt/lib/python3.11/site-packages/transformers/integrations/peft.py:399: FutureWarning: The `active_adapter` method is deprecated and will be removed in a future version.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cluster/home/terjenf/.conda/envs/vgdebatt/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "adapter_state_dict = model.get_adapter_state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'MistralForCausalLM' object has no attribute 'add_adapters'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[51], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model\u001b[38;5;241m.\u001b[39madd_adapters(lora_state_dict, wegith_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzero3\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.conda/envs/vgdebatt/lib/python3.11/site-packages/torch/nn/modules/module.py:1709\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1707\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[1;32m   1708\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[0;32m-> 1709\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'MistralForCausalLM' object has no attribute 'add_adapters'"
     ]
    }
   ],
   "source": [
    "model.add_adapters(lora_state_dict, wegith_name=\"zero3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lora_state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "291"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(base_state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 4096]) base_model.model.model.layers.0.self_attn.q_proj.lora_A.default.weight\n",
      "torch.Size([4096, 16]) base_model.model.model.layers.0.self_attn.q_proj.lora_B.default.weight\n",
      "torch.Size([16, 4096]) base_model.model.model.layers.0.self_attn.v_proj.lora_A.default.weight\n",
      "torch.Size([1024, 16]) base_model.model.model.layers.0.self_attn.v_proj.lora_B.default.weight\n",
      "torch.Size([16, 4096]) base_model.model.model.layers.1.self_attn.q_proj.lora_A.default.weight\n",
      "torch.Size([4096, 16]) base_model.model.model.layers.1.self_attn.q_proj.lora_B.default.weight\n",
      "torch.Size([16, 4096]) base_model.model.model.layers.1.self_attn.v_proj.lora_A.default.weight\n",
      "torch.Size([1024, 16]) base_model.model.model.layers.1.self_attn.v_proj.lora_B.default.weight\n",
      "torch.Size([16, 4096]) base_model.model.model.layers.2.self_attn.q_proj.lora_A.default.weight\n",
      "torch.Size([4096, 16]) base_model.model.model.layers.2.self_attn.q_proj.lora_B.default.weight\n",
      "torch.Size([16, 4096]) base_model.model.model.layers.2.self_attn.v_proj.lora_A.default.weight\n",
      "torch.Size([1024, 16]) base_model.model.model.layers.2.self_attn.v_proj.lora_B.default.weight\n",
      "torch.Size([16, 4096]) base_model.model.model.layers.3.self_attn.q_proj.lora_A.default.weight\n",
      "torch.Size([4096, 16]) base_model.model.model.layers.3.self_attn.q_proj.lora_B.default.weight\n",
      "torch.Size([16, 4096]) base_model.model.model.layers.3.self_attn.v_proj.lora_A.default.weight\n",
      "torch.Size([1024, 16]) base_model.model.model.layers.3.self_attn.v_proj.lora_B.default.weight\n",
      "torch.Size([16, 4096]) base_model.model.model.layers.4.self_attn.q_proj.lora_A.default.weight\n",
      "torch.Size([4096, 16]) base_model.model.model.layers.4.self_attn.q_proj.lora_B.default.weight\n",
      "torch.Size([16, 4096]) base_model.model.model.layers.4.self_attn.v_proj.lora_A.default.weight\n",
      "torch.Size([1024, 16]) base_model.model.model.layers.4.self_attn.v_proj.lora_B.default.weight\n",
      "torch.Size([16, 4096]) base_model.model.model.layers.5.self_attn.q_proj.lora_A.default.weight\n",
      "torch.Size([4096, 16]) base_model.model.model.layers.5.self_attn.q_proj.lora_B.default.weight\n",
      "torch.Size([16, 4096]) base_model.model.model.layers.5.self_attn.v_proj.lora_A.default.weight\n",
      "torch.Size([1024, 16]) base_model.model.model.layers.5.self_attn.v_proj.lora_B.default.weight\n",
      "torch.Size([16, 4096]) base_model.model.model.layers.6.self_attn.q_proj.lora_A.default.weight\n",
      "torch.Size([4096, 16]) base_model.model.model.layers.6.self_attn.q_proj.lora_B.default.weight\n",
      "torch.Size([16, 4096]) base_model.model.model.layers.6.self_attn.v_proj.lora_A.default.weight\n",
      "torch.Size([1024, 16]) base_model.model.model.layers.6.self_attn.v_proj.lora_B.default.weight\n",
      "torch.Size([16, 4096]) base_model.model.model.layers.7.self_attn.q_proj.lora_A.default.weight\n",
      "torch.Size([4096, 16]) base_model.model.model.layers.7.self_attn.q_proj.lora_B.default.weight\n",
      "torch.Size([16, 4096]) base_model.model.model.layers.7.self_attn.v_proj.lora_A.default.weight\n",
      "torch.Size([1024, 16]) base_model.model.model.layers.7.self_attn.v_proj.lora_B.default.weight\n",
      "torch.Size([16, 4096]) base_model.model.model.layers.8.self_attn.q_proj.lora_A.default.weight\n",
      "torch.Size([4096, 16]) base_model.model.model.layers.8.self_attn.q_proj.lora_B.default.weight\n",
      "torch.Size([16, 4096]) base_model.model.model.layers.8.self_attn.v_proj.lora_A.default.weight\n",
      "torch.Size([1024, 16]) base_model.model.model.layers.8.self_attn.v_proj.lora_B.default.weight\n",
      "torch.Size([16, 4096]) base_model.model.model.layers.9.self_attn.q_proj.lora_A.default.weight\n",
      "torch.Size([4096, 16]) base_model.model.model.layers.9.self_attn.q_proj.lora_B.default.weight\n",
      "torch.Size([16, 4096]) base_model.model.model.layers.9.self_attn.v_proj.lora_A.default.weight\n",
      "torch.Size([1024, 16]) base_model.model.model.layers.9.self_attn.v_proj.lora_B.default.weight\n",
      "torch.Size([16, 4096]) base_model.model.model.layers.10.self_attn.q_proj.lora_A.default.weight\n",
      "torch.Size([4096, 16]) base_model.model.model.layers.10.self_attn.q_proj.lora_B.default.weight\n",
      "torch.Size([16, 4096]) base_model.model.model.layers.10.self_attn.v_proj.lora_A.default.weight\n",
      "torch.Size([1024, 16]) base_model.model.model.layers.10.self_attn.v_proj.lora_B.default.weight\n",
      "torch.Size([16, 4096]) base_model.model.model.layers.11.self_attn.q_proj.lora_A.default.weight\n",
      "torch.Size([4096, 16]) base_model.model.model.layers.11.self_attn.q_proj.lora_B.default.weight\n",
      "torch.Size([16, 4096]) base_model.model.model.layers.11.self_attn.v_proj.lora_A.default.weight\n",
      "torch.Size([1024, 16]) base_model.model.model.layers.11.self_attn.v_proj.lora_B.default.weight\n",
      "torch.Size([16, 4096]) base_model.model.model.layers.12.self_attn.q_proj.lora_A.default.weight\n",
      "torch.Size([4096, 16]) base_model.model.model.layers.12.self_attn.q_proj.lora_B.default.weight\n",
      "torch.Size([16, 4096]) base_model.model.model.layers.12.self_attn.v_proj.lora_A.default.weight\n",
      "torch.Size([1024, 16]) base_model.model.model.layers.12.self_attn.v_proj.lora_B.default.weight\n",
      "torch.Size([16, 4096]) base_model.model.model.layers.13.self_attn.q_proj.lora_A.default.weight\n",
      "torch.Size([4096, 16]) base_model.model.model.layers.13.self_attn.q_proj.lora_B.default.weight\n",
      "torch.Size([16, 4096]) base_model.model.model.layers.13.self_attn.v_proj.lora_A.default.weight\n",
      "torch.Size([1024, 16]) base_model.model.model.layers.13.self_attn.v_proj.lora_B.default.weight\n",
      "torch.Size([16, 4096]) base_model.model.model.layers.14.self_attn.q_proj.lora_A.default.weight\n",
      "torch.Size([4096, 16]) base_model.model.model.layers.14.self_attn.q_proj.lora_B.default.weight\n",
      "torch.Size([16, 4096]) base_model.model.model.layers.14.self_attn.v_proj.lora_A.default.weight\n",
      "torch.Size([1024, 16]) base_model.model.model.layers.14.self_attn.v_proj.lora_B.default.weight\n",
      "torch.Size([16, 4096]) base_model.model.model.layers.15.self_attn.q_proj.lora_A.default.weight\n",
      "torch.Size([4096, 16]) base_model.model.model.layers.15.self_attn.q_proj.lora_B.default.weight\n",
      "torch.Size([16, 4096]) base_model.model.model.layers.15.self_attn.v_proj.lora_A.default.weight\n",
      "torch.Size([1024, 16]) base_model.model.model.layers.15.self_attn.v_proj.lora_B.default.weight\n",
      "torch.Size([16, 4096]) base_model.model.model.layers.16.self_attn.q_proj.lora_A.default.weight\n",
      "torch.Size([4096, 16]) base_model.model.model.layers.16.self_attn.q_proj.lora_B.default.weight\n",
      "torch.Size([16, 4096]) base_model.model.model.layers.16.self_attn.v_proj.lora_A.default.weight\n",
      "torch.Size([1024, 16]) base_model.model.model.layers.16.self_attn.v_proj.lora_B.default.weight\n",
      "torch.Size([16, 4096]) base_model.model.model.layers.17.self_attn.q_proj.lora_A.default.weight\n",
      "torch.Size([4096, 16]) base_model.model.model.layers.17.self_attn.q_proj.lora_B.default.weight\n",
      "torch.Size([16, 4096]) base_model.model.model.layers.17.self_attn.v_proj.lora_A.default.weight\n",
      "torch.Size([1024, 16]) base_model.model.model.layers.17.self_attn.v_proj.lora_B.default.weight\n",
      "torch.Size([16, 4096]) base_model.model.model.layers.18.self_attn.q_proj.lora_A.default.weight\n",
      "torch.Size([4096, 16]) base_model.model.model.layers.18.self_attn.q_proj.lora_B.default.weight\n",
      "torch.Size([16, 4096]) base_model.model.model.layers.18.self_attn.v_proj.lora_A.default.weight\n",
      "torch.Size([1024, 16]) base_model.model.model.layers.18.self_attn.v_proj.lora_B.default.weight\n",
      "torch.Size([16, 4096]) base_model.model.model.layers.19.self_attn.q_proj.lora_A.default.weight\n",
      "torch.Size([4096, 16]) base_model.model.model.layers.19.self_attn.q_proj.lora_B.default.weight\n",
      "torch.Size([16, 4096]) base_model.model.model.layers.19.self_attn.v_proj.lora_A.default.weight\n",
      "torch.Size([1024, 16]) base_model.model.model.layers.19.self_attn.v_proj.lora_B.default.weight\n",
      "torch.Size([16, 4096]) base_model.model.model.layers.20.self_attn.q_proj.lora_A.default.weight\n",
      "torch.Size([4096, 16]) base_model.model.model.layers.20.self_attn.q_proj.lora_B.default.weight\n",
      "torch.Size([16, 4096]) base_model.model.model.layers.20.self_attn.v_proj.lora_A.default.weight\n",
      "torch.Size([1024, 16]) base_model.model.model.layers.20.self_attn.v_proj.lora_B.default.weight\n",
      "torch.Size([16, 4096]) base_model.model.model.layers.21.self_attn.q_proj.lora_A.default.weight\n",
      "torch.Size([4096, 16]) base_model.model.model.layers.21.self_attn.q_proj.lora_B.default.weight\n",
      "torch.Size([16, 4096]) base_model.model.model.layers.21.self_attn.v_proj.lora_A.default.weight\n",
      "torch.Size([1024, 16]) base_model.model.model.layers.21.self_attn.v_proj.lora_B.default.weight\n",
      "torch.Size([16, 4096]) base_model.model.model.layers.22.self_attn.q_proj.lora_A.default.weight\n",
      "torch.Size([4096, 16]) base_model.model.model.layers.22.self_attn.q_proj.lora_B.default.weight\n",
      "torch.Size([16, 4096]) base_model.model.model.layers.22.self_attn.v_proj.lora_A.default.weight\n",
      "torch.Size([1024, 16]) base_model.model.model.layers.22.self_attn.v_proj.lora_B.default.weight\n",
      "torch.Size([16, 4096]) base_model.model.model.layers.23.self_attn.q_proj.lora_A.default.weight\n",
      "torch.Size([4096, 16]) base_model.model.model.layers.23.self_attn.q_proj.lora_B.default.weight\n",
      "torch.Size([16, 4096]) base_model.model.model.layers.23.self_attn.v_proj.lora_A.default.weight\n",
      "torch.Size([1024, 16]) base_model.model.model.layers.23.self_attn.v_proj.lora_B.default.weight\n",
      "torch.Size([16, 4096]) base_model.model.model.layers.24.self_attn.q_proj.lora_A.default.weight\n",
      "torch.Size([4096, 16]) base_model.model.model.layers.24.self_attn.q_proj.lora_B.default.weight\n",
      "torch.Size([16, 4096]) base_model.model.model.layers.24.self_attn.v_proj.lora_A.default.weight\n",
      "torch.Size([1024, 16]) base_model.model.model.layers.24.self_attn.v_proj.lora_B.default.weight\n",
      "torch.Size([16, 4096]) base_model.model.model.layers.25.self_attn.q_proj.lora_A.default.weight\n",
      "torch.Size([4096, 16]) base_model.model.model.layers.25.self_attn.q_proj.lora_B.default.weight\n",
      "torch.Size([16, 4096]) base_model.model.model.layers.25.self_attn.v_proj.lora_A.default.weight\n",
      "torch.Size([1024, 16]) base_model.model.model.layers.25.self_attn.v_proj.lora_B.default.weight\n",
      "torch.Size([16, 4096]) base_model.model.model.layers.26.self_attn.q_proj.lora_A.default.weight\n",
      "torch.Size([4096, 16]) base_model.model.model.layers.26.self_attn.q_proj.lora_B.default.weight\n",
      "torch.Size([16, 4096]) base_model.model.model.layers.26.self_attn.v_proj.lora_A.default.weight\n",
      "torch.Size([1024, 16]) base_model.model.model.layers.26.self_attn.v_proj.lora_B.default.weight\n",
      "torch.Size([16, 4096]) base_model.model.model.layers.27.self_attn.q_proj.lora_A.default.weight\n",
      "torch.Size([4096, 16]) base_model.model.model.layers.27.self_attn.q_proj.lora_B.default.weight\n",
      "torch.Size([16, 4096]) base_model.model.model.layers.27.self_attn.v_proj.lora_A.default.weight\n",
      "torch.Size([1024, 16]) base_model.model.model.layers.27.self_attn.v_proj.lora_B.default.weight\n",
      "torch.Size([16, 4096]) base_model.model.model.layers.28.self_attn.q_proj.lora_A.default.weight\n",
      "torch.Size([4096, 16]) base_model.model.model.layers.28.self_attn.q_proj.lora_B.default.weight\n",
      "torch.Size([16, 4096]) base_model.model.model.layers.28.self_attn.v_proj.lora_A.default.weight\n",
      "torch.Size([1024, 16]) base_model.model.model.layers.28.self_attn.v_proj.lora_B.default.weight\n",
      "torch.Size([16, 4096]) base_model.model.model.layers.29.self_attn.q_proj.lora_A.default.weight\n",
      "torch.Size([4096, 16]) base_model.model.model.layers.29.self_attn.q_proj.lora_B.default.weight\n",
      "torch.Size([16, 4096]) base_model.model.model.layers.29.self_attn.v_proj.lora_A.default.weight\n",
      "torch.Size([1024, 16]) base_model.model.model.layers.29.self_attn.v_proj.lora_B.default.weight\n",
      "torch.Size([16, 4096]) base_model.model.model.layers.30.self_attn.q_proj.lora_A.default.weight\n",
      "torch.Size([4096, 16]) base_model.model.model.layers.30.self_attn.q_proj.lora_B.default.weight\n",
      "torch.Size([16, 4096]) base_model.model.model.layers.30.self_attn.v_proj.lora_A.default.weight\n",
      "torch.Size([1024, 16]) base_model.model.model.layers.30.self_attn.v_proj.lora_B.default.weight\n",
      "torch.Size([16, 4096]) base_model.model.model.layers.31.self_attn.q_proj.lora_A.default.weight\n",
      "torch.Size([4096, 16]) base_model.model.model.layers.31.self_attn.q_proj.lora_B.default.weight\n",
      "torch.Size([16, 4096]) base_model.model.model.layers.31.self_attn.v_proj.lora_A.default.weight\n",
      "torch.Size([1024, 16]) base_model.model.model.layers.31.self_attn.v_proj.lora_B.default.weight\n"
     ]
    }
   ],
   "source": [
    "for state in lora_state_dict.keys():\n",
    "    print(lora_state_dict.get(state).shape, state)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([67993, 4096]) model.embed_tokens.weight\n",
      "torch.Size([4096, 4096]) model.layers.0.self_attn.q_proj.weight\n",
      "torch.Size([1024, 4096]) model.layers.0.self_attn.k_proj.weight\n",
      "torch.Size([1024, 4096]) model.layers.0.self_attn.v_proj.weight\n",
      "torch.Size([4096, 4096]) model.layers.0.self_attn.o_proj.weight\n",
      "torch.Size([14336, 4096]) model.layers.0.mlp.gate_proj.weight\n",
      "torch.Size([14336, 4096]) model.layers.0.mlp.up_proj.weight\n",
      "torch.Size([4096, 14336]) model.layers.0.mlp.down_proj.weight\n",
      "torch.Size([4096]) model.layers.0.input_layernorm.weight\n",
      "torch.Size([4096]) model.layers.0.post_attention_layernorm.weight\n",
      "torch.Size([4096, 4096]) model.layers.1.self_attn.q_proj.weight\n",
      "torch.Size([1024, 4096]) model.layers.1.self_attn.k_proj.weight\n",
      "torch.Size([1024, 4096]) model.layers.1.self_attn.v_proj.weight\n",
      "torch.Size([4096, 4096]) model.layers.1.self_attn.o_proj.weight\n",
      "torch.Size([14336, 4096]) model.layers.1.mlp.gate_proj.weight\n",
      "torch.Size([14336, 4096]) model.layers.1.mlp.up_proj.weight\n",
      "torch.Size([4096, 14336]) model.layers.1.mlp.down_proj.weight\n",
      "torch.Size([4096]) model.layers.1.input_layernorm.weight\n",
      "torch.Size([4096]) model.layers.1.post_attention_layernorm.weight\n",
      "torch.Size([4096, 4096]) model.layers.2.self_attn.q_proj.weight\n",
      "torch.Size([1024, 4096]) model.layers.2.self_attn.k_proj.weight\n",
      "torch.Size([1024, 4096]) model.layers.2.self_attn.v_proj.weight\n",
      "torch.Size([4096, 4096]) model.layers.2.self_attn.o_proj.weight\n",
      "torch.Size([14336, 4096]) model.layers.2.mlp.gate_proj.weight\n",
      "torch.Size([14336, 4096]) model.layers.2.mlp.up_proj.weight\n",
      "torch.Size([4096, 14336]) model.layers.2.mlp.down_proj.weight\n",
      "torch.Size([4096]) model.layers.2.input_layernorm.weight\n",
      "torch.Size([4096]) model.layers.2.post_attention_layernorm.weight\n",
      "torch.Size([4096, 4096]) model.layers.3.self_attn.q_proj.weight\n",
      "torch.Size([1024, 4096]) model.layers.3.self_attn.k_proj.weight\n",
      "torch.Size([1024, 4096]) model.layers.3.self_attn.v_proj.weight\n",
      "torch.Size([4096, 4096]) model.layers.3.self_attn.o_proj.weight\n",
      "torch.Size([14336, 4096]) model.layers.3.mlp.gate_proj.weight\n",
      "torch.Size([14336, 4096]) model.layers.3.mlp.up_proj.weight\n",
      "torch.Size([4096, 14336]) model.layers.3.mlp.down_proj.weight\n",
      "torch.Size([4096]) model.layers.3.input_layernorm.weight\n",
      "torch.Size([4096]) model.layers.3.post_attention_layernorm.weight\n",
      "torch.Size([4096, 4096]) model.layers.4.self_attn.q_proj.weight\n",
      "torch.Size([1024, 4096]) model.layers.4.self_attn.k_proj.weight\n",
      "torch.Size([1024, 4096]) model.layers.4.self_attn.v_proj.weight\n",
      "torch.Size([4096, 4096]) model.layers.4.self_attn.o_proj.weight\n",
      "torch.Size([14336, 4096]) model.layers.4.mlp.gate_proj.weight\n",
      "torch.Size([14336, 4096]) model.layers.4.mlp.up_proj.weight\n",
      "torch.Size([4096, 14336]) model.layers.4.mlp.down_proj.weight\n",
      "torch.Size([4096]) model.layers.4.input_layernorm.weight\n",
      "torch.Size([4096]) model.layers.4.post_attention_layernorm.weight\n",
      "torch.Size([4096, 4096]) model.layers.5.self_attn.q_proj.weight\n",
      "torch.Size([1024, 4096]) model.layers.5.self_attn.k_proj.weight\n",
      "torch.Size([1024, 4096]) model.layers.5.self_attn.v_proj.weight\n",
      "torch.Size([4096, 4096]) model.layers.5.self_attn.o_proj.weight\n",
      "torch.Size([14336, 4096]) model.layers.5.mlp.gate_proj.weight\n",
      "torch.Size([14336, 4096]) model.layers.5.mlp.up_proj.weight\n",
      "torch.Size([4096, 14336]) model.layers.5.mlp.down_proj.weight\n",
      "torch.Size([4096]) model.layers.5.input_layernorm.weight\n",
      "torch.Size([4096]) model.layers.5.post_attention_layernorm.weight\n",
      "torch.Size([4096, 4096]) model.layers.6.self_attn.q_proj.weight\n",
      "torch.Size([1024, 4096]) model.layers.6.self_attn.k_proj.weight\n",
      "torch.Size([1024, 4096]) model.layers.6.self_attn.v_proj.weight\n",
      "torch.Size([4096, 4096]) model.layers.6.self_attn.o_proj.weight\n",
      "torch.Size([14336, 4096]) model.layers.6.mlp.gate_proj.weight\n",
      "torch.Size([14336, 4096]) model.layers.6.mlp.up_proj.weight\n",
      "torch.Size([4096, 14336]) model.layers.6.mlp.down_proj.weight\n",
      "torch.Size([4096]) model.layers.6.input_layernorm.weight\n",
      "torch.Size([4096]) model.layers.6.post_attention_layernorm.weight\n",
      "torch.Size([4096, 4096]) model.layers.7.self_attn.q_proj.weight\n",
      "torch.Size([1024, 4096]) model.layers.7.self_attn.k_proj.weight\n",
      "torch.Size([1024, 4096]) model.layers.7.self_attn.v_proj.weight\n",
      "torch.Size([4096, 4096]) model.layers.7.self_attn.o_proj.weight\n",
      "torch.Size([14336, 4096]) model.layers.7.mlp.gate_proj.weight\n",
      "torch.Size([14336, 4096]) model.layers.7.mlp.up_proj.weight\n",
      "torch.Size([4096, 14336]) model.layers.7.mlp.down_proj.weight\n",
      "torch.Size([4096]) model.layers.7.input_layernorm.weight\n",
      "torch.Size([4096]) model.layers.7.post_attention_layernorm.weight\n",
      "torch.Size([4096, 4096]) model.layers.8.self_attn.q_proj.weight\n",
      "torch.Size([1024, 4096]) model.layers.8.self_attn.k_proj.weight\n",
      "torch.Size([1024, 4096]) model.layers.8.self_attn.v_proj.weight\n",
      "torch.Size([4096, 4096]) model.layers.8.self_attn.o_proj.weight\n",
      "torch.Size([14336, 4096]) model.layers.8.mlp.gate_proj.weight\n",
      "torch.Size([14336, 4096]) model.layers.8.mlp.up_proj.weight\n",
      "torch.Size([4096, 14336]) model.layers.8.mlp.down_proj.weight\n",
      "torch.Size([4096]) model.layers.8.input_layernorm.weight\n",
      "torch.Size([4096]) model.layers.8.post_attention_layernorm.weight\n",
      "torch.Size([4096, 4096]) model.layers.9.self_attn.q_proj.weight\n",
      "torch.Size([1024, 4096]) model.layers.9.self_attn.k_proj.weight\n",
      "torch.Size([1024, 4096]) model.layers.9.self_attn.v_proj.weight\n",
      "torch.Size([4096, 4096]) model.layers.9.self_attn.o_proj.weight\n",
      "torch.Size([14336, 4096]) model.layers.9.mlp.gate_proj.weight\n",
      "torch.Size([14336, 4096]) model.layers.9.mlp.up_proj.weight\n",
      "torch.Size([4096, 14336]) model.layers.9.mlp.down_proj.weight\n",
      "torch.Size([4096]) model.layers.9.input_layernorm.weight\n",
      "torch.Size([4096]) model.layers.9.post_attention_layernorm.weight\n",
      "torch.Size([4096, 4096]) model.layers.10.self_attn.q_proj.weight\n",
      "torch.Size([1024, 4096]) model.layers.10.self_attn.k_proj.weight\n",
      "torch.Size([1024, 4096]) model.layers.10.self_attn.v_proj.weight\n",
      "torch.Size([4096, 4096]) model.layers.10.self_attn.o_proj.weight\n",
      "torch.Size([14336, 4096]) model.layers.10.mlp.gate_proj.weight\n",
      "torch.Size([14336, 4096]) model.layers.10.mlp.up_proj.weight\n",
      "torch.Size([4096, 14336]) model.layers.10.mlp.down_proj.weight\n",
      "torch.Size([4096]) model.layers.10.input_layernorm.weight\n",
      "torch.Size([4096]) model.layers.10.post_attention_layernorm.weight\n",
      "torch.Size([4096, 4096]) model.layers.11.self_attn.q_proj.weight\n",
      "torch.Size([1024, 4096]) model.layers.11.self_attn.k_proj.weight\n",
      "torch.Size([1024, 4096]) model.layers.11.self_attn.v_proj.weight\n",
      "torch.Size([4096, 4096]) model.layers.11.self_attn.o_proj.weight\n",
      "torch.Size([14336, 4096]) model.layers.11.mlp.gate_proj.weight\n",
      "torch.Size([14336, 4096]) model.layers.11.mlp.up_proj.weight\n",
      "torch.Size([4096, 14336]) model.layers.11.mlp.down_proj.weight\n",
      "torch.Size([4096]) model.layers.11.input_layernorm.weight\n",
      "torch.Size([4096]) model.layers.11.post_attention_layernorm.weight\n",
      "torch.Size([4096, 4096]) model.layers.12.self_attn.q_proj.weight\n",
      "torch.Size([1024, 4096]) model.layers.12.self_attn.k_proj.weight\n",
      "torch.Size([1024, 4096]) model.layers.12.self_attn.v_proj.weight\n",
      "torch.Size([4096, 4096]) model.layers.12.self_attn.o_proj.weight\n",
      "torch.Size([14336, 4096]) model.layers.12.mlp.gate_proj.weight\n",
      "torch.Size([14336, 4096]) model.layers.12.mlp.up_proj.weight\n",
      "torch.Size([4096, 14336]) model.layers.12.mlp.down_proj.weight\n",
      "torch.Size([4096]) model.layers.12.input_layernorm.weight\n",
      "torch.Size([4096]) model.layers.12.post_attention_layernorm.weight\n",
      "torch.Size([4096, 4096]) model.layers.13.self_attn.q_proj.weight\n",
      "torch.Size([1024, 4096]) model.layers.13.self_attn.k_proj.weight\n",
      "torch.Size([1024, 4096]) model.layers.13.self_attn.v_proj.weight\n",
      "torch.Size([4096, 4096]) model.layers.13.self_attn.o_proj.weight\n",
      "torch.Size([14336, 4096]) model.layers.13.mlp.gate_proj.weight\n",
      "torch.Size([14336, 4096]) model.layers.13.mlp.up_proj.weight\n",
      "torch.Size([4096, 14336]) model.layers.13.mlp.down_proj.weight\n",
      "torch.Size([4096]) model.layers.13.input_layernorm.weight\n",
      "torch.Size([4096]) model.layers.13.post_attention_layernorm.weight\n",
      "torch.Size([4096, 4096]) model.layers.14.self_attn.q_proj.weight\n",
      "torch.Size([1024, 4096]) model.layers.14.self_attn.k_proj.weight\n",
      "torch.Size([1024, 4096]) model.layers.14.self_attn.v_proj.weight\n",
      "torch.Size([4096, 4096]) model.layers.14.self_attn.o_proj.weight\n",
      "torch.Size([14336, 4096]) model.layers.14.mlp.gate_proj.weight\n",
      "torch.Size([14336, 4096]) model.layers.14.mlp.up_proj.weight\n",
      "torch.Size([4096, 14336]) model.layers.14.mlp.down_proj.weight\n",
      "torch.Size([4096]) model.layers.14.input_layernorm.weight\n",
      "torch.Size([4096]) model.layers.14.post_attention_layernorm.weight\n",
      "torch.Size([4096, 4096]) model.layers.15.self_attn.q_proj.weight\n",
      "torch.Size([1024, 4096]) model.layers.15.self_attn.k_proj.weight\n",
      "torch.Size([1024, 4096]) model.layers.15.self_attn.v_proj.weight\n",
      "torch.Size([4096, 4096]) model.layers.15.self_attn.o_proj.weight\n",
      "torch.Size([14336, 4096]) model.layers.15.mlp.gate_proj.weight\n",
      "torch.Size([14336, 4096]) model.layers.15.mlp.up_proj.weight\n",
      "torch.Size([4096, 14336]) model.layers.15.mlp.down_proj.weight\n",
      "torch.Size([4096]) model.layers.15.input_layernorm.weight\n",
      "torch.Size([4096]) model.layers.15.post_attention_layernorm.weight\n",
      "torch.Size([4096, 4096]) model.layers.16.self_attn.q_proj.weight\n",
      "torch.Size([1024, 4096]) model.layers.16.self_attn.k_proj.weight\n",
      "torch.Size([1024, 4096]) model.layers.16.self_attn.v_proj.weight\n",
      "torch.Size([4096, 4096]) model.layers.16.self_attn.o_proj.weight\n",
      "torch.Size([14336, 4096]) model.layers.16.mlp.gate_proj.weight\n",
      "torch.Size([14336, 4096]) model.layers.16.mlp.up_proj.weight\n",
      "torch.Size([4096, 14336]) model.layers.16.mlp.down_proj.weight\n",
      "torch.Size([4096]) model.layers.16.input_layernorm.weight\n",
      "torch.Size([4096]) model.layers.16.post_attention_layernorm.weight\n",
      "torch.Size([4096, 4096]) model.layers.17.self_attn.q_proj.weight\n",
      "torch.Size([1024, 4096]) model.layers.17.self_attn.k_proj.weight\n",
      "torch.Size([1024, 4096]) model.layers.17.self_attn.v_proj.weight\n",
      "torch.Size([4096, 4096]) model.layers.17.self_attn.o_proj.weight\n",
      "torch.Size([14336, 4096]) model.layers.17.mlp.gate_proj.weight\n",
      "torch.Size([14336, 4096]) model.layers.17.mlp.up_proj.weight\n",
      "torch.Size([4096, 14336]) model.layers.17.mlp.down_proj.weight\n",
      "torch.Size([4096]) model.layers.17.input_layernorm.weight\n",
      "torch.Size([4096]) model.layers.17.post_attention_layernorm.weight\n",
      "torch.Size([4096, 4096]) model.layers.18.self_attn.q_proj.weight\n",
      "torch.Size([1024, 4096]) model.layers.18.self_attn.k_proj.weight\n",
      "torch.Size([1024, 4096]) model.layers.18.self_attn.v_proj.weight\n",
      "torch.Size([4096, 4096]) model.layers.18.self_attn.o_proj.weight\n",
      "torch.Size([14336, 4096]) model.layers.18.mlp.gate_proj.weight\n",
      "torch.Size([14336, 4096]) model.layers.18.mlp.up_proj.weight\n",
      "torch.Size([4096, 14336]) model.layers.18.mlp.down_proj.weight\n",
      "torch.Size([4096]) model.layers.18.input_layernorm.weight\n",
      "torch.Size([4096]) model.layers.18.post_attention_layernorm.weight\n",
      "torch.Size([4096, 4096]) model.layers.19.self_attn.q_proj.weight\n",
      "torch.Size([1024, 4096]) model.layers.19.self_attn.k_proj.weight\n",
      "torch.Size([1024, 4096]) model.layers.19.self_attn.v_proj.weight\n",
      "torch.Size([4096, 4096]) model.layers.19.self_attn.o_proj.weight\n",
      "torch.Size([14336, 4096]) model.layers.19.mlp.gate_proj.weight\n",
      "torch.Size([14336, 4096]) model.layers.19.mlp.up_proj.weight\n",
      "torch.Size([4096, 14336]) model.layers.19.mlp.down_proj.weight\n",
      "torch.Size([4096]) model.layers.19.input_layernorm.weight\n",
      "torch.Size([4096]) model.layers.19.post_attention_layernorm.weight\n",
      "torch.Size([4096, 4096]) model.layers.20.self_attn.q_proj.weight\n",
      "torch.Size([1024, 4096]) model.layers.20.self_attn.k_proj.weight\n",
      "torch.Size([1024, 4096]) model.layers.20.self_attn.v_proj.weight\n",
      "torch.Size([4096, 4096]) model.layers.20.self_attn.o_proj.weight\n",
      "torch.Size([14336, 4096]) model.layers.20.mlp.gate_proj.weight\n",
      "torch.Size([14336, 4096]) model.layers.20.mlp.up_proj.weight\n",
      "torch.Size([4096, 14336]) model.layers.20.mlp.down_proj.weight\n",
      "torch.Size([4096]) model.layers.20.input_layernorm.weight\n",
      "torch.Size([4096]) model.layers.20.post_attention_layernorm.weight\n",
      "torch.Size([4096, 4096]) model.layers.21.self_attn.q_proj.weight\n",
      "torch.Size([1024, 4096]) model.layers.21.self_attn.k_proj.weight\n",
      "torch.Size([1024, 4096]) model.layers.21.self_attn.v_proj.weight\n",
      "torch.Size([4096, 4096]) model.layers.21.self_attn.o_proj.weight\n",
      "torch.Size([14336, 4096]) model.layers.21.mlp.gate_proj.weight\n",
      "torch.Size([14336, 4096]) model.layers.21.mlp.up_proj.weight\n",
      "torch.Size([4096, 14336]) model.layers.21.mlp.down_proj.weight\n",
      "torch.Size([4096]) model.layers.21.input_layernorm.weight\n",
      "torch.Size([4096]) model.layers.21.post_attention_layernorm.weight\n",
      "torch.Size([4096, 4096]) model.layers.22.self_attn.q_proj.weight\n",
      "torch.Size([1024, 4096]) model.layers.22.self_attn.k_proj.weight\n",
      "torch.Size([1024, 4096]) model.layers.22.self_attn.v_proj.weight\n",
      "torch.Size([4096, 4096]) model.layers.22.self_attn.o_proj.weight\n",
      "torch.Size([14336, 4096]) model.layers.22.mlp.gate_proj.weight\n",
      "torch.Size([14336, 4096]) model.layers.22.mlp.up_proj.weight\n",
      "torch.Size([4096, 14336]) model.layers.22.mlp.down_proj.weight\n",
      "torch.Size([4096]) model.layers.22.input_layernorm.weight\n",
      "torch.Size([4096]) model.layers.22.post_attention_layernorm.weight\n",
      "torch.Size([4096, 4096]) model.layers.23.self_attn.q_proj.weight\n",
      "torch.Size([1024, 4096]) model.layers.23.self_attn.k_proj.weight\n",
      "torch.Size([1024, 4096]) model.layers.23.self_attn.v_proj.weight\n",
      "torch.Size([4096, 4096]) model.layers.23.self_attn.o_proj.weight\n",
      "torch.Size([14336, 4096]) model.layers.23.mlp.gate_proj.weight\n",
      "torch.Size([14336, 4096]) model.layers.23.mlp.up_proj.weight\n",
      "torch.Size([4096, 14336]) model.layers.23.mlp.down_proj.weight\n",
      "torch.Size([4096]) model.layers.23.input_layernorm.weight\n",
      "torch.Size([4096]) model.layers.23.post_attention_layernorm.weight\n",
      "torch.Size([4096, 4096]) model.layers.24.self_attn.q_proj.weight\n",
      "torch.Size([1024, 4096]) model.layers.24.self_attn.k_proj.weight\n",
      "torch.Size([1024, 4096]) model.layers.24.self_attn.v_proj.weight\n",
      "torch.Size([4096, 4096]) model.layers.24.self_attn.o_proj.weight\n",
      "torch.Size([14336, 4096]) model.layers.24.mlp.gate_proj.weight\n",
      "torch.Size([14336, 4096]) model.layers.24.mlp.up_proj.weight\n",
      "torch.Size([4096, 14336]) model.layers.24.mlp.down_proj.weight\n",
      "torch.Size([4096]) model.layers.24.input_layernorm.weight\n",
      "torch.Size([4096]) model.layers.24.post_attention_layernorm.weight\n",
      "torch.Size([4096, 4096]) model.layers.25.self_attn.q_proj.weight\n",
      "torch.Size([1024, 4096]) model.layers.25.self_attn.k_proj.weight\n",
      "torch.Size([1024, 4096]) model.layers.25.self_attn.v_proj.weight\n",
      "torch.Size([4096, 4096]) model.layers.25.self_attn.o_proj.weight\n",
      "torch.Size([14336, 4096]) model.layers.25.mlp.gate_proj.weight\n",
      "torch.Size([14336, 4096]) model.layers.25.mlp.up_proj.weight\n",
      "torch.Size([4096, 14336]) model.layers.25.mlp.down_proj.weight\n",
      "torch.Size([4096]) model.layers.25.input_layernorm.weight\n",
      "torch.Size([4096]) model.layers.25.post_attention_layernorm.weight\n",
      "torch.Size([4096, 4096]) model.layers.26.self_attn.q_proj.weight\n",
      "torch.Size([1024, 4096]) model.layers.26.self_attn.k_proj.weight\n",
      "torch.Size([1024, 4096]) model.layers.26.self_attn.v_proj.weight\n",
      "torch.Size([4096, 4096]) model.layers.26.self_attn.o_proj.weight\n",
      "torch.Size([14336, 4096]) model.layers.26.mlp.gate_proj.weight\n",
      "torch.Size([14336, 4096]) model.layers.26.mlp.up_proj.weight\n",
      "torch.Size([4096, 14336]) model.layers.26.mlp.down_proj.weight\n",
      "torch.Size([4096]) model.layers.26.input_layernorm.weight\n",
      "torch.Size([4096]) model.layers.26.post_attention_layernorm.weight\n",
      "torch.Size([4096, 4096]) model.layers.27.self_attn.q_proj.weight\n",
      "torch.Size([1024, 4096]) model.layers.27.self_attn.k_proj.weight\n",
      "torch.Size([1024, 4096]) model.layers.27.self_attn.v_proj.weight\n",
      "torch.Size([4096, 4096]) model.layers.27.self_attn.o_proj.weight\n",
      "torch.Size([14336, 4096]) model.layers.27.mlp.gate_proj.weight\n",
      "torch.Size([14336, 4096]) model.layers.27.mlp.up_proj.weight\n",
      "torch.Size([4096, 14336]) model.layers.27.mlp.down_proj.weight\n",
      "torch.Size([4096]) model.layers.27.input_layernorm.weight\n",
      "torch.Size([4096]) model.layers.27.post_attention_layernorm.weight\n",
      "torch.Size([4096, 4096]) model.layers.28.self_attn.q_proj.weight\n",
      "torch.Size([1024, 4096]) model.layers.28.self_attn.k_proj.weight\n",
      "torch.Size([1024, 4096]) model.layers.28.self_attn.v_proj.weight\n",
      "torch.Size([4096, 4096]) model.layers.28.self_attn.o_proj.weight\n",
      "torch.Size([14336, 4096]) model.layers.28.mlp.gate_proj.weight\n",
      "torch.Size([14336, 4096]) model.layers.28.mlp.up_proj.weight\n",
      "torch.Size([4096, 14336]) model.layers.28.mlp.down_proj.weight\n",
      "torch.Size([4096]) model.layers.28.input_layernorm.weight\n",
      "torch.Size([4096]) model.layers.28.post_attention_layernorm.weight\n",
      "torch.Size([4096, 4096]) model.layers.29.self_attn.q_proj.weight\n",
      "torch.Size([1024, 4096]) model.layers.29.self_attn.k_proj.weight\n",
      "torch.Size([1024, 4096]) model.layers.29.self_attn.v_proj.weight\n",
      "torch.Size([4096, 4096]) model.layers.29.self_attn.o_proj.weight\n",
      "torch.Size([14336, 4096]) model.layers.29.mlp.gate_proj.weight\n",
      "torch.Size([14336, 4096]) model.layers.29.mlp.up_proj.weight\n",
      "torch.Size([4096, 14336]) model.layers.29.mlp.down_proj.weight\n",
      "torch.Size([4096]) model.layers.29.input_layernorm.weight\n",
      "torch.Size([4096]) model.layers.29.post_attention_layernorm.weight\n",
      "torch.Size([4096, 4096]) model.layers.30.self_attn.q_proj.weight\n",
      "torch.Size([1024, 4096]) model.layers.30.self_attn.k_proj.weight\n",
      "torch.Size([1024, 4096]) model.layers.30.self_attn.v_proj.weight\n",
      "torch.Size([4096, 4096]) model.layers.30.self_attn.o_proj.weight\n",
      "torch.Size([14336, 4096]) model.layers.30.mlp.gate_proj.weight\n",
      "torch.Size([14336, 4096]) model.layers.30.mlp.up_proj.weight\n",
      "torch.Size([4096, 14336]) model.layers.30.mlp.down_proj.weight\n",
      "torch.Size([4096]) model.layers.30.input_layernorm.weight\n",
      "torch.Size([4096]) model.layers.30.post_attention_layernorm.weight\n",
      "torch.Size([4096, 4096]) model.layers.31.self_attn.q_proj.weight\n",
      "torch.Size([1024, 4096]) model.layers.31.self_attn.k_proj.weight\n",
      "torch.Size([1024, 4096]) model.layers.31.self_attn.v_proj.weight\n",
      "torch.Size([4096, 4096]) model.layers.31.self_attn.o_proj.weight\n",
      "torch.Size([14336, 4096]) model.layers.31.mlp.gate_proj.weight\n",
      "torch.Size([14336, 4096]) model.layers.31.mlp.up_proj.weight\n",
      "torch.Size([4096, 14336]) model.layers.31.mlp.down_proj.weight\n",
      "torch.Size([4096]) model.layers.31.input_layernorm.weight\n",
      "torch.Size([4096]) model.layers.31.post_attention_layernorm.weight\n",
      "torch.Size([4096]) model.norm.weight\n",
      "torch.Size([67993, 4096]) lm_head.weight\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "291"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(base_state_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0099,  0.0508, -0.0007,  ..., -0.0313, -0.0046,  0.0463],\n",
      "        [ 0.0074, -0.0108, -0.0074,  ...,  0.0257,  0.0021,  0.0282],\n",
      "        [ 0.0165, -0.0406, -0.0053,  ..., -0.0101,  0.0094, -0.0284],\n",
      "        ...,\n",
      "        [-0.0180,  0.0013,  0.0021,  ...,  0.0304, -0.0095, -0.0048],\n",
      "        [-0.0029,  0.0155, -0.0128,  ...,  0.0160, -0.0106, -0.0380],\n",
      "        [-0.0062,  0.0096, -0.0147,  ..., -0.0474,  0.0018, -0.0128]],\n",
      "       grad_fn=<ViewBackward0>)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MistralForCausalLM' object has no attribute 'peft_config'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m adapter \u001b[38;5;129;01min\u001b[39;00m state_dict\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(state_dict\u001b[38;5;241m.\u001b[39mget(adapter))\n\u001b[0;32m----> 3\u001b[0m     model\u001b[38;5;241m.\u001b[39mset_adapter(state_dict\u001b[38;5;241m.\u001b[39mget(adapter))\n",
      "File \u001b[0;32m~/.conda/envs/vgdebatt/lib/python3.11/site-packages/transformers/integrations/peft.py:297\u001b[0m, in \u001b[0;36mPeftAdapterMixin.set_adapter\u001b[0;34m(self, adapter_name)\u001b[0m\n\u001b[1;32m    292\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(missing) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    293\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    294\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFollowing adapter(s) could not be found: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(missing)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Make sure you are passing the correct adapter name(s).\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    295\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m current loaded adapters are: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpeft_config\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    296\u001b[0m         )\n\u001b[0;32m--> 297\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m adapter_name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpeft_config:\n\u001b[1;32m    298\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    299\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAdapter with name \u001b[39m\u001b[38;5;132;01m{\u001b[39;00madapter_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not found. Please pass the correct adapter name among \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpeft_config\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    300\u001b[0m     )\n\u001b[1;32m    302\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpeft\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtuners\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtuners_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseTunerLayer\n",
      "File \u001b[0;32m~/.conda/envs/vgdebatt/lib/python3.11/site-packages/torch/nn/modules/module.py:1709\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1707\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[1;32m   1708\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[0;32m-> 1709\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'MistralForCausalLM' object has no attribute 'peft_config'"
     ]
    }
   ],
   "source": [
    "\n",
    "for adapter in state_dict.keys():\n",
    "    print(state_dict.get(adapter))\n",
    "    model.set_adapter(state_dict.get(adapter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "249d5fe97cce4f6cb3f0864324b8f90f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for MistralForCausalLM:\n\tMissing key(s) in state_dict: \"model.embed_tokens.weight\", \"model.layers.0.self_attn.q_proj.weight\", \"model.layers.0.self_attn.k_proj.weight\", \"model.layers.0.self_attn.v_proj.weight\", \"model.layers.0.self_attn.o_proj.weight\", \"model.layers.0.mlp.gate_proj.weight\", \"model.layers.0.mlp.up_proj.weight\", \"model.layers.0.mlp.down_proj.weight\", \"model.layers.0.input_layernorm.weight\", \"model.layers.0.post_attention_layernorm.weight\", \"model.layers.1.self_attn.q_proj.weight\", \"model.layers.1.self_attn.k_proj.weight\", \"model.layers.1.self_attn.v_proj.weight\", \"model.layers.1.self_attn.o_proj.weight\", \"model.layers.1.mlp.gate_proj.weight\", \"model.layers.1.mlp.up_proj.weight\", \"model.layers.1.mlp.down_proj.weight\", \"model.layers.1.input_layernorm.weight\", \"model.layers.1.post_attention_layernorm.weight\", \"model.layers.2.self_attn.q_proj.weight\", \"model.layers.2.self_attn.k_proj.weight\", \"model.layers.2.self_attn.v_proj.weight\", \"model.layers.2.self_attn.o_proj.weight\", \"model.layers.2.mlp.gate_proj.weight\", \"model.layers.2.mlp.up_proj.weight\", \"model.layers.2.mlp.down_proj.weight\", \"model.layers.2.input_layernorm.weight\", \"model.layers.2.post_attention_layernorm.weight\", \"model.layers.3.self_attn.q_proj.weight\", \"model.layers.3.self_attn.k_proj.weight\", \"model.layers.3.self_attn.v_proj.weight\", \"model.layers.3.self_attn.o_proj.weight\", \"model.layers.3.mlp.gate_proj.weight\", \"model.layers.3.mlp.up_proj.weight\", \"model.layers.3.mlp.down_proj.weight\", \"model.layers.3.input_layernorm.weight\", \"model.layers.3.post_attention_layernorm.weight\", \"model.layers.4.self_attn.q_proj.weight\", \"model.layers.4.self_attn.k_proj.weight\", \"model.layers.4.self_attn.v_proj.weight\", \"model.layers.4.self_attn.o_proj.weight\", \"model.layers.4.mlp.gate_proj.weight\", \"model.layers.4.mlp.up_proj.weight\", \"model.layers.4.mlp.down_proj.weight\", \"model.layers.4.input_layernorm.weight\", \"model.layers.4.post_attention_layernorm.weight\", \"model.layers.5.self_attn.q_proj.weight\", \"model.layers.5.self_attn.k_proj.weight\", \"model.layers.5.self_attn.v_proj.weight\", \"model.layers.5.self_attn.o_proj.weight\", \"model.layers.5.mlp.gate_proj.weight\", \"model.layers.5.mlp.up_proj.weight\", \"model.layers.5.mlp.down_proj.weight\", \"model.layers.5.input_layernorm.weight\", \"model.layers.5.post_attention_layernorm.weight\", \"model.layers.6.self_attn.q_proj.weight\", \"model.layers.6.self_attn.k_proj.weight\", \"model.layers.6.self_attn.v_proj.weight\", \"model.layers.6.self_attn.o_proj.weight\", \"model.layers.6.mlp.gate_proj.weight\", \"model.layers.6.mlp.up_proj.weight\", \"model.layers.6.mlp.down_proj.weight\", \"model.layers.6.input_layernorm.weight\", \"model.layers.6.post_attention_layernorm.weight\", \"model.layers.7.self_attn.q_proj.weight\", \"model.layers.7.self_attn.k_proj.weight\", \"model.layers.7.self_attn.v_proj.weight\", \"model.layers.7.self_attn.o_proj.weight\", \"model.layers.7.mlp.gate_proj.weight\", \"model.layers.7.mlp.up_proj.weight\", \"model.layers.7.mlp.down_proj.weight\", \"model.layers.7.input_layernorm.weight\", \"model.layers.7.post_attention_layernorm.weight\", \"model.layers.8.self_attn.q_proj.weight\", \"model.layers.8.self_attn.k_proj.weight\", \"model.layers.8.self_attn.v_proj.weight\", \"model.layers.8.self_attn.o_proj.weight\", \"model.layers.8.mlp.gate_proj.weight\", \"model.layers.8.mlp.up_proj.weight\", \"model.layers.8.mlp.down_proj.weight\", \"model.layers.8.input_layernorm.weight\", \"model.layers.8.post_attention_layernorm.weight\", \"model.layers.9.self_attn.q_proj.weight\", \"model.layers.9.self_attn.k_proj.weight\", \"model.layers.9.self_attn.v_proj.weight\", \"model.layers.9.self_attn.o_proj.weight\", \"model.layers.9.mlp.gate_proj.weight\", \"model.layers.9.mlp.up_proj.weight\", \"model.layers.9.mlp.down_proj.weight\", \"model.layers.9.input_layernorm.weight\", \"model.layers.9.post_attention_layernorm.weight\", \"model.layers.10.self_attn.q_proj.weight\", \"model.layers.10.self_attn.k_proj.weight\", \"model.layers.10.self_attn.v_proj.weight\", \"model.layers.10.self_attn.o_proj.weight\", \"model.layers.10.mlp.gate_proj.weight\", \"model.layers.10.mlp.up_proj.weight\", \"model.layers.10.mlp.down_proj.weight\", \"model.layers.10.input_layernorm.weight\", \"model.layers.10.post_attention_layernorm.weight\", \"model.layers.11.self_attn.q_proj.weight\", \"model.layers.11.self_attn.k_proj.weight\", \"model.layers.11.self_attn.v_proj.weight\", \"model.layers.11.self_attn.o_proj.weight\", \"model.layers.11.mlp.gate_proj.weight\", \"model.layers.11.mlp.up_proj.weight\", \"model.layers.11.mlp.down_proj.weight\", \"model.layers.11.input_layernorm.weight\", \"model.layers.11.post_attention_layernorm.weight\", \"model.layers.12.self_attn.q_proj.weight\", \"model.layers.12.self_attn.k_proj.weight\", \"model.layers.12.self_attn.v_proj.weight\", \"model.layers.12.self_attn.o_proj.weight\", \"model.layers.12.mlp.gate_proj.weight\", \"model.layers.12.mlp.up_proj.weight\", \"model.layers.12.mlp.down_proj.weight\", \"model.layers.12.input_layernorm.weight\", \"model.layers.12.post_attention_layernorm.weight\", \"model.layers.13.self_attn.q_proj.weight\", \"model.layers.13.self_attn.k_proj.weight\", \"model.layers.13.self_attn.v_proj.weight\", \"model.layers.13.self_attn.o_proj.weight\", \"model.layers.13.mlp.gate_proj.weight\", \"model.layers.13.mlp.up_proj.weight\", \"model.layers.13.mlp.down_proj.weight\", \"model.layers.13.input_layernorm.weight\", \"model.layers.13.post_attention_layernorm.weight\", \"model.layers.14.self_attn.q_proj.weight\", \"model.layers.14.self_attn.k_proj.weight\", \"model.layers.14.self_attn.v_proj.weight\", \"model.layers.14.self_attn.o_proj.weight\", \"model.layers.14.mlp.gate_proj.weight\", \"model.layers.14.mlp.up_proj.weight\", \"model.layers.14.mlp.down_proj.weight\", \"model.layers.14.input_layernorm.weight\", \"model.layers.14.post_attention_layernorm.weight\", \"model.layers.15.self_attn.q_proj.weight\", \"model.layers.15.self_attn.k_proj.weight\", \"model.layers.15.self_attn.v_proj.weight\", \"model.layers.15.self_attn.o_proj.weight\", \"model.layers.15.mlp.gate_proj.weight\", \"model.layers.15.mlp.up_proj.weight\", \"model.layers.15.mlp.down_proj.weight\", \"model.layers.15.input_layernorm.weight\", \"model.layers.15.post_attention_layernorm.weight\", \"model.layers.16.self_attn.q_proj.weight\", \"model.layers.16.self_attn.k_proj.weight\", \"model.layers.16.self_attn.v_proj.weight\", \"model.layers.16.self_attn.o_proj.weight\", \"model.layers.16.mlp.gate_proj.weight\", \"model.layers.16.mlp.up_proj.weight\", \"model.layers.16.mlp.down_proj.weight\", \"model.layers.16.input_layernorm.weight\", \"model.layers.16.post_attention_layernorm.weight\", \"model.layers.17.self_attn.q_proj.weight\", \"model.layers.17.self_attn.k_proj.weight\", \"model.layers.17.self_attn.v_proj.weight\", \"model.layers.17.self_attn.o_proj.weight\", \"model.layers.17.mlp.gate_proj.weight\", \"model.layers.17.mlp.up_proj.weight\", \"model.layers.17.mlp.down_proj.weight\", \"model.layers.17.input_layernorm.weight\", \"model.layers.17.post_attention_layernorm.weight\", \"model.layers.18.self_attn.q_proj.weight\", \"model.layers.18.self_attn.k_proj.weight\", \"model.layers.18.self_attn.v_proj.weight\", \"model.layers.18.self_attn.o_proj.weight\", \"model.layers.18.mlp.gate_proj.weight\", \"model.layers.18.mlp.up_proj.weight\", \"model.layers.18.mlp.down_proj.weight\", \"model.layers.18.input_layernorm.weight\", \"model.layers.18.post_attention_layernorm.weight\", \"model.layers.19.self_attn.q_proj.weight\", \"model.layers.19.self_attn.k_proj.weight\", \"model.layers.19.self_attn.v_proj.weight\", \"model.layers.19.self_attn.o_proj.weight\", \"model.layers.19.mlp.gate_proj.weight\", \"model.layers.19.mlp.up_proj.weight\", \"model.layers.19.mlp.down_proj.weight\", \"model.layers.19.input_layernorm.weight\", \"model.layers.19.post_attention_layernorm.weight\", \"model.layers.20.self_attn.q_proj.weight\", \"model.layers.20.self_attn.k_proj.weight\", \"model.layers.20.self_attn.v_proj.weight\", \"model.layers.20.self_attn.o_proj.weight\", \"model.layers.20.mlp.gate_proj.weight\", \"model.layers.20.mlp.up_proj.weight\", \"model.layers.20.mlp.down_proj.weight\", \"model.layers.20.input_layernorm.weight\", \"model.layers.20.post_attention_layernorm.weight\", \"model.layers.21.self_attn.q_proj.weight\", \"model.layers.21.self_attn.k_proj.weight\", \"model.layers.21.self_attn.v_proj.weight\", \"model.layers.21.self_attn.o_proj.weight\", \"model.layers.21.mlp.gate_proj.weight\", \"model.layers.21.mlp.up_proj.weight\", \"model.layers.21.mlp.down_proj.weight\", \"model.layers.21.input_layernorm.weight\", \"model.layers.21.post_attention_layernorm.weight\", \"model.layers.22.self_attn.q_proj.weight\", \"model.layers.22.self_attn.k_proj.weight\", \"model.layers.22.self_attn.v_proj.weight\", \"model.layers.22.self_attn.o_proj.weight\", \"model.layers.22.mlp.gate_proj.weight\", \"model.layers.22.mlp.up_proj.weight\", \"model.layers.22.mlp.down_proj.weight\", \"model.layers.22.input_layernorm.weight\", \"model.layers.22.post_attention_layernorm.weight\", \"model.layers.23.self_attn.q_proj.weight\", \"model.layers.23.self_attn.k_proj.weight\", \"model.layers.23.self_attn.v_proj.weight\", \"model.layers.23.self_attn.o_proj.weight\", \"model.layers.23.mlp.gate_proj.weight\", \"model.layers.23.mlp.up_proj.weight\", \"model.layers.23.mlp.down_proj.weight\", \"model.layers.23.input_layernorm.weight\", \"model.layers.23.post_attention_layernorm.weight\", \"model.layers.24.self_attn.q_proj.weight\", \"model.layers.24.self_attn.k_proj.weight\", \"model.layers.24.self_attn.v_proj.weight\", \"model.layers.24.self_attn.o_proj.weight\", \"model.layers.24.mlp.gate_proj.weight\", \"model.layers.24.mlp.up_proj.weight\", \"model.layers.24.mlp.down_proj.weight\", \"model.layers.24.input_layernorm.weight\", \"model.layers.24.post_attention_layernorm.weight\", \"model.layers.25.self_attn.q_proj.weight\", \"model.layers.25.self_attn.k_proj.weight\", \"model.layers.25.self_attn.v_proj.weight\", \"model.layers.25.self_attn.o_proj.weight\", \"model.layers.25.mlp.gate_proj.weight\", \"model.layers.25.mlp.up_proj.weight\", \"model.layers.25.mlp.down_proj.weight\", \"model.layers.25.input_layernorm.weight\", \"model.layers.25.post_attention_layernorm.weight\", \"model.layers.26.self_attn.q_proj.weight\", \"model.layers.26.self_attn.k_proj.weight\", \"model.layers.26.self_attn.v_proj.weight\", \"model.layers.26.self_attn.o_proj.weight\", \"model.layers.26.mlp.gate_proj.weight\", \"model.layers.26.mlp.up_proj.weight\", \"model.layers.26.mlp.down_proj.weight\", \"model.layers.26.input_layernorm.weight\", \"model.layers.26.post_attention_layernorm.weight\", \"model.layers.27.self_attn.q_proj.weight\", \"model.layers.27.self_attn.k_proj.weight\", \"model.layers.27.self_attn.v_proj.weight\", \"model.layers.27.self_attn.o_proj.weight\", \"model.layers.27.mlp.gate_proj.weight\", \"model.layers.27.mlp.up_proj.weight\", \"model.layers.27.mlp.down_proj.weight\", \"model.layers.27.input_layernorm.weight\", \"model.layers.27.post_attention_layernorm.weight\", \"model.layers.28.self_attn.q_proj.weight\", \"model.layers.28.self_attn.k_proj.weight\", \"model.layers.28.self_attn.v_proj.weight\", \"model.layers.28.self_attn.o_proj.weight\", \"model.layers.28.mlp.gate_proj.weight\", \"model.layers.28.mlp.up_proj.weight\", \"model.layers.28.mlp.down_proj.weight\", \"model.layers.28.input_layernorm.weight\", \"model.layers.28.post_attention_layernorm.weight\", \"model.layers.29.self_attn.q_proj.weight\", \"model.layers.29.self_attn.k_proj.weight\", \"model.layers.29.self_attn.v_proj.weight\", \"model.layers.29.self_attn.o_proj.weight\", \"model.layers.29.mlp.gate_proj.weight\", \"model.layers.29.mlp.up_proj.weight\", \"model.layers.29.mlp.down_proj.weight\", \"model.layers.29.input_layernorm.weight\", \"model.layers.29.post_attention_layernorm.weight\", \"model.layers.30.self_attn.q_proj.weight\", \"model.layers.30.self_attn.k_proj.weight\", \"model.layers.30.self_attn.v_proj.weight\", \"model.layers.30.self_attn.o_proj.weight\", \"model.layers.30.mlp.gate_proj.weight\", \"model.layers.30.mlp.up_proj.weight\", \"model.layers.30.mlp.down_proj.weight\", \"model.layers.30.input_layernorm.weight\", \"model.layers.30.post_attention_layernorm.weight\", \"model.layers.31.self_attn.q_proj.weight\", \"model.layers.31.self_attn.k_proj.weight\", \"model.layers.31.self_attn.v_proj.weight\", \"model.layers.31.self_attn.o_proj.weight\", \"model.layers.31.mlp.gate_proj.weight\", \"model.layers.31.mlp.up_proj.weight\", \"model.layers.31.mlp.down_proj.weight\", \"model.layers.31.input_layernorm.weight\", \"model.layers.31.post_attention_layernorm.weight\", \"model.norm.weight\", \"lm_head.weight\". \n\tUnexpected key(s) in state_dict: \"base_model.model.model.layers.0.self_attn.q_proj.lora_A.default.weight\", \"base_model.model.model.layers.0.self_attn.q_proj.lora_B.default.weight\", \"base_model.model.model.layers.0.self_attn.v_proj.lora_A.default.weight\", \"base_model.model.model.layers.0.self_attn.v_proj.lora_B.default.weight\", \"base_model.model.model.layers.1.self_attn.q_proj.lora_A.default.weight\", \"base_model.model.model.layers.1.self_attn.q_proj.lora_B.default.weight\", \"base_model.model.model.layers.1.self_attn.v_proj.lora_A.default.weight\", \"base_model.model.model.layers.1.self_attn.v_proj.lora_B.default.weight\", \"base_model.model.model.layers.2.self_attn.q_proj.lora_A.default.weight\", \"base_model.model.model.layers.2.self_attn.q_proj.lora_B.default.weight\", \"base_model.model.model.layers.2.self_attn.v_proj.lora_A.default.weight\", \"base_model.model.model.layers.2.self_attn.v_proj.lora_B.default.weight\", \"base_model.model.model.layers.3.self_attn.q_proj.lora_A.default.weight\", \"base_model.model.model.layers.3.self_attn.q_proj.lora_B.default.weight\", \"base_model.model.model.layers.3.self_attn.v_proj.lora_A.default.weight\", \"base_model.model.model.layers.3.self_attn.v_proj.lora_B.default.weight\", \"base_model.model.model.layers.4.self_attn.q_proj.lora_A.default.weight\", \"base_model.model.model.layers.4.self_attn.q_proj.lora_B.default.weight\", \"base_model.model.model.layers.4.self_attn.v_proj.lora_A.default.weight\", \"base_model.model.model.layers.4.self_attn.v_proj.lora_B.default.weight\", \"base_model.model.model.layers.5.self_attn.q_proj.lora_A.default.weight\", \"base_model.model.model.layers.5.self_attn.q_proj.lora_B.default.weight\", \"base_model.model.model.layers.5.self_attn.v_proj.lora_A.default.weight\", \"base_model.model.model.layers.5.self_attn.v_proj.lora_B.default.weight\", \"base_model.model.model.layers.6.self_attn.q_proj.lora_A.default.weight\", \"base_model.model.model.layers.6.self_attn.q_proj.lora_B.default.weight\", \"base_model.model.model.layers.6.self_attn.v_proj.lora_A.default.weight\", \"base_model.model.model.layers.6.self_attn.v_proj.lora_B.default.weight\", \"base_model.model.model.layers.7.self_attn.q_proj.lora_A.default.weight\", \"base_model.model.model.layers.7.self_attn.q_proj.lora_B.default.weight\", \"base_model.model.model.layers.7.self_attn.v_proj.lora_A.default.weight\", \"base_model.model.model.layers.7.self_attn.v_proj.lora_B.default.weight\", \"base_model.model.model.layers.8.self_attn.q_proj.lora_A.default.weight\", \"base_model.model.model.layers.8.self_attn.q_proj.lora_B.default.weight\", \"base_model.model.model.layers.8.self_attn.v_proj.lora_A.default.weight\", \"base_model.model.model.layers.8.self_attn.v_proj.lora_B.default.weight\", \"base_model.model.model.layers.9.self_attn.q_proj.lora_A.default.weight\", \"base_model.model.model.layers.9.self_attn.q_proj.lora_B.default.weight\", \"base_model.model.model.layers.9.self_attn.v_proj.lora_A.default.weight\", \"base_model.model.model.layers.9.self_attn.v_proj.lora_B.default.weight\", \"base_model.model.model.layers.10.self_attn.q_proj.lora_A.default.weight\", \"base_model.model.model.layers.10.self_attn.q_proj.lora_B.default.weight\", \"base_model.model.model.layers.10.self_attn.v_proj.lora_A.default.weight\", \"base_model.model.model.layers.10.self_attn.v_proj.lora_B.default.weight\", \"base_model.model.model.layers.11.self_attn.q_proj.lora_A.default.weight\", \"base_model.model.model.layers.11.self_attn.q_proj.lora_B.default.weight\", \"base_model.model.model.layers.11.self_attn.v_proj.lora_A.default.weight\", \"base_model.model.model.layers.11.self_attn.v_proj.lora_B.default.weight\", \"base_model.model.model.layers.12.self_attn.q_proj.lora_A.default.weight\", \"base_model.model.model.layers.12.self_attn.q_proj.lora_B.default.weight\", \"base_model.model.model.layers.12.self_attn.v_proj.lora_A.default.weight\", \"base_model.model.model.layers.12.self_attn.v_proj.lora_B.default.weight\", \"base_model.model.model.layers.13.self_attn.q_proj.lora_A.default.weight\", \"base_model.model.model.layers.13.self_attn.q_proj.lora_B.default.weight\", \"base_model.model.model.layers.13.self_attn.v_proj.lora_A.default.weight\", \"base_model.model.model.layers.13.self_attn.v_proj.lora_B.default.weight\", \"base_model.model.model.layers.14.self_attn.q_proj.lora_A.default.weight\", \"base_model.model.model.layers.14.self_attn.q_proj.lora_B.default.weight\", \"base_model.model.model.layers.14.self_attn.v_proj.lora_A.default.weight\", \"base_model.model.model.layers.14.self_attn.v_proj.lora_B.default.weight\", \"base_model.model.model.layers.15.self_attn.q_proj.lora_A.default.weight\", \"base_model.model.model.layers.15.self_attn.q_proj.lora_B.default.weight\", \"base_model.model.model.layers.15.self_attn.v_proj.lora_A.default.weight\", \"base_model.model.model.layers.15.self_attn.v_proj.lora_B.default.weight\", \"base_model.model.model.layers.16.self_attn.q_proj.lora_A.default.weight\", \"base_model.model.model.layers.16.self_attn.q_proj.lora_B.default.weight\", \"base_model.model.model.layers.16.self_attn.v_proj.lora_A.default.weight\", \"base_model.model.model.layers.16.self_attn.v_proj.lora_B.default.weight\", \"base_model.model.model.layers.17.self_attn.q_proj.lora_A.default.weight\", \"base_model.model.model.layers.17.self_attn.q_proj.lora_B.default.weight\", \"base_model.model.model.layers.17.self_attn.v_proj.lora_A.default.weight\", \"base_model.model.model.layers.17.self_attn.v_proj.lora_B.default.weight\", \"base_model.model.model.layers.18.self_attn.q_proj.lora_A.default.weight\", \"base_model.model.model.layers.18.self_attn.q_proj.lora_B.default.weight\", \"base_model.model.model.layers.18.self_attn.v_proj.lora_A.default.weight\", \"base_model.model.model.layers.18.self_attn.v_proj.lora_B.default.weight\", \"base_model.model.model.layers.19.self_attn.q_proj.lora_A.default.weight\", \"base_model.model.model.layers.19.self_attn.q_proj.lora_B.default.weight\", \"base_model.model.model.layers.19.self_attn.v_proj.lora_A.default.weight\", \"base_model.model.model.layers.19.self_attn.v_proj.lora_B.default.weight\", \"base_model.model.model.layers.20.self_attn.q_proj.lora_A.default.weight\", \"base_model.model.model.layers.20.self_attn.q_proj.lora_B.default.weight\", \"base_model.model.model.layers.20.self_attn.v_proj.lora_A.default.weight\", \"base_model.model.model.layers.20.self_attn.v_proj.lora_B.default.weight\", \"base_model.model.model.layers.21.self_attn.q_proj.lora_A.default.weight\", \"base_model.model.model.layers.21.self_attn.q_proj.lora_B.default.weight\", \"base_model.model.model.layers.21.self_attn.v_proj.lora_A.default.weight\", \"base_model.model.model.layers.21.self_attn.v_proj.lora_B.default.weight\", \"base_model.model.model.layers.22.self_attn.q_proj.lora_A.default.weight\", \"base_model.model.model.layers.22.self_attn.q_proj.lora_B.default.weight\", \"base_model.model.model.layers.22.self_attn.v_proj.lora_A.default.weight\", \"base_model.model.model.layers.22.self_attn.v_proj.lora_B.default.weight\", \"base_model.model.model.layers.23.self_attn.q_proj.lora_A.default.weight\", \"base_model.model.model.layers.23.self_attn.q_proj.lora_B.default.weight\", \"base_model.model.model.layers.23.self_attn.v_proj.lora_A.default.weight\", \"base_model.model.model.layers.23.self_attn.v_proj.lora_B.default.weight\", \"base_model.model.model.layers.24.self_attn.q_proj.lora_A.default.weight\", \"base_model.model.model.layers.24.self_attn.q_proj.lora_B.default.weight\", \"base_model.model.model.layers.24.self_attn.v_proj.lora_A.default.weight\", \"base_model.model.model.layers.24.self_attn.v_proj.lora_B.default.weight\", \"base_model.model.model.layers.25.self_attn.q_proj.lora_A.default.weight\", \"base_model.model.model.layers.25.self_attn.q_proj.lora_B.default.weight\", \"base_model.model.model.layers.25.self_attn.v_proj.lora_A.default.weight\", \"base_model.model.model.layers.25.self_attn.v_proj.lora_B.default.weight\", \"base_model.model.model.layers.26.self_attn.q_proj.lora_A.default.weight\", \"base_model.model.model.layers.26.self_attn.q_proj.lora_B.default.weight\", \"base_model.model.model.layers.26.self_attn.v_proj.lora_A.default.weight\", \"base_model.model.model.layers.26.self_attn.v_proj.lora_B.default.weight\", \"base_model.model.model.layers.27.self_attn.q_proj.lora_A.default.weight\", \"base_model.model.model.layers.27.self_attn.q_proj.lora_B.default.weight\", \"base_model.model.model.layers.27.self_attn.v_proj.lora_A.default.weight\", \"base_model.model.model.layers.27.self_attn.v_proj.lora_B.default.weight\", \"base_model.model.model.layers.28.self_attn.q_proj.lora_A.default.weight\", \"base_model.model.model.layers.28.self_attn.q_proj.lora_B.default.weight\", \"base_model.model.model.layers.28.self_attn.v_proj.lora_A.default.weight\", \"base_model.model.model.layers.28.self_attn.v_proj.lora_B.default.weight\", \"base_model.model.model.layers.29.self_attn.q_proj.lora_A.default.weight\", \"base_model.model.model.layers.29.self_attn.q_proj.lora_B.default.weight\", \"base_model.model.model.layers.29.self_attn.v_proj.lora_A.default.weight\", \"base_model.model.model.layers.29.self_attn.v_proj.lora_B.default.weight\", \"base_model.model.model.layers.30.self_attn.q_proj.lora_A.default.weight\", \"base_model.model.model.layers.30.self_attn.q_proj.lora_B.default.weight\", \"base_model.model.model.layers.30.self_attn.v_proj.lora_A.default.weight\", \"base_model.model.model.layers.30.self_attn.v_proj.lora_B.default.weight\", \"base_model.model.model.layers.31.self_attn.q_proj.lora_A.default.weight\", \"base_model.model.model.layers.31.self_attn.q_proj.lora_B.default.weight\", \"base_model.model.model.layers.31.self_attn.v_proj.lora_A.default.weight\", \"base_model.model.model.layers.31.self_attn.v_proj.lora_B.default.weight\". ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model\u001b[38;5;241m.\u001b[39mload_state_dict(state_dict)\n",
      "File \u001b[0;32m~/.conda/envs/vgdebatt/lib/python3.11/site-packages/torch/nn/modules/module.py:2189\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[0;34m(self, state_dict, strict, assign)\u001b[0m\n\u001b[1;32m   2184\u001b[0m         error_msgs\u001b[38;5;241m.\u001b[39minsert(\n\u001b[1;32m   2185\u001b[0m             \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMissing key(s) in state_dict: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2186\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m missing_keys)))\n\u001b[1;32m   2188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 2189\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2190\u001b[0m                        \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(error_msgs)))\n\u001b[1;32m   2191\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for MistralForCausalLM:\n\tMissing key(s) in state_dict: \"model.embed_tokens.weight\", \"model.layers.0.self_attn.q_proj.weight\", \"model.layers.0.self_attn.k_proj.weight\", \"model.layers.0.self_attn.v_proj.weight\", \"model.layers.0.self_attn.o_proj.weight\", \"model.layers.0.mlp.gate_proj.weight\", \"model.layers.0.mlp.up_proj.weight\", \"model.layers.0.mlp.down_proj.weight\", \"model.layers.0.input_layernorm.weight\", \"model.layers.0.post_attention_layernorm.weight\", \"model.layers.1.self_attn.q_proj.weight\", \"model.layers.1.self_attn.k_proj.weight\", \"model.layers.1.self_attn.v_proj.weight\", \"model.layers.1.self_attn.o_proj.weight\", \"model.layers.1.mlp.gate_proj.weight\", \"model.layers.1.mlp.up_proj.weight\", \"model.layers.1.mlp.down_proj.weight\", \"model.layers.1.input_layernorm.weight\", \"model.layers.1.post_attention_layernorm.weight\", \"model.layers.2.self_attn.q_proj.weight\", \"model.layers.2.self_attn.k_proj.weight\", \"model.layers.2.self_attn.v_proj.weight\", \"model.layers.2.self_attn.o_proj.weight\", \"model.layers.2.mlp.gate_proj.weight\", \"model.layers.2.mlp.up_proj.weight\", \"model.layers.2.mlp.down_proj.weight\", \"model.layers.2.input_layernorm.weight\", \"model.layers.2.post_attention_layernorm.weight\", \"model.layers.3.self_attn.q_proj.weight\", \"model.layers.3.self_attn.k_proj.weight\", \"model.layers.3.self_attn.v_proj.weight\", \"model.layers.3.self_attn.o_proj.weight\", \"model.layers.3.mlp.gate_proj.weight\", \"model.layers.3.mlp.up_proj.weight\", \"model.layers.3.mlp.down_proj.weight\", \"model.layers.3.input_layernorm.weight\", \"model.layers.3.post_attention_layernorm.weight\", \"model.layers.4.self_attn.q_proj.weight\", \"model.layers.4.self_attn.k_proj.weight\", \"model.layers.4.self_attn.v_proj.weight\", \"model.layers.4.self_attn.o_proj.weight\", \"model.layers.4.mlp.gate_proj.weight\", \"model.layers.4.mlp.up_proj.weight\", \"model.layers.4.mlp.down_proj.weight\", \"model.layers.4.input_layernorm.weight\", \"model.layers.4.post_attention_layernorm.weight\", \"model.layers.5.self_attn.q_proj.weight\", \"model.layers.5.self_attn.k_proj.weight\", \"model.layers.5.self_attn.v_proj.weight\", \"model.layers.5.self_attn.o_proj.weight\", \"model.layers.5.mlp.gate_proj.weight\", \"model.layers.5.mlp.up_proj.weight\", \"model.layers.5.mlp.down_proj.weight\", \"model.layers.5.input_layernorm.weight\", \"model.layers.5.post_attention_layernorm.weight\", \"model.layers.6.self_attn.q_proj.weight\", \"model.layers.6.self_attn.k_proj.weight\", \"model.layers.6.self_attn.v_proj.weight\", \"model.layers.6.self_attn.o_proj.weight\", \"model.layers.6.mlp.gate_proj.weight\", \"model.layers.6.mlp.up_proj.weight\", \"model.layers.6.mlp.down_proj.weight\", \"model.layers.6.input_layernorm.weight\", \"model.layers.6.post_attention_layernorm.weight\", \"model.layers.7.self_attn.q_proj.weight\", \"model.layers.7.self_attn.k_proj.weight\", \"model.layers.7.self_attn.v_proj.weight\", \"model.layers.7.self_attn.o_proj.weight\", \"model.layers.7.mlp.gate_proj.weight\", \"model.layers.7.mlp.up_proj.weight\", \"model.layers.7.mlp.down_proj.weight\", \"model.layers.7.input_layernorm.weight\", \"model.layers.7.post_attention_layernorm.weight\", \"model.layers.8.self_attn.q_proj.weight\", \"model.layers.8.self_attn.k_proj.weight\", \"model.layers.8.self_attn.v_proj.weight\", \"model.layers.8.self_attn.o_proj.weight\", \"model.layers.8.mlp.gate_proj.weight\", \"model.layers.8.mlp.up_proj.weight\", \"model.layers.8.mlp.down_proj.weight\", \"model.layers.8.input_layernorm.weight\", \"model.layers.8.post_attention_layernorm.weight\", \"model.layers.9.self_attn.q_proj.weight\", \"model.layers.9.self_attn.k_proj.weight\", \"model.layers.9.self_attn.v_proj.weight\", \"model.layers.9.self_attn.o_proj.weight\", \"model.layers.9.mlp.gate_proj.weight\", \"model.layers.9.mlp.up_proj.weight\", \"model.layers.9.mlp.down_proj.weight\", \"model.layers.9.input_layernorm.weight\", \"model.layers.9.post_attention_layernorm.weight\", \"model.layers.10.self_attn.q_proj.weight\", \"model.layers.10.self_attn.k_proj.weight\", \"model.layers.10.self_attn.v_proj.weight\", \"model.layers.10.self_attn.o_proj.weight\", \"model.layers.10.mlp.gate_proj.weight\", \"model.layers.10.mlp.up_proj.weight\", \"model.layers.10.mlp.down_proj.weight\", \"model.layers.10.input_layernorm.weight\", \"model.layers.10.post_attention_layernorm.weight\", \"model.layers.11.self_attn.q_proj.weight\", \"model.layers.11.self_attn.k_proj.weight\", \"model.layers.11.self_attn.v_proj.weight\", \"model.layers.11.self_attn.o_proj.weight\", \"model.layers.11.mlp.gate_proj.weight\", \"model.layers.11.mlp.up_proj.weight\", \"model.layers.11.mlp.down_proj.weight\", \"model.layers.11.input_layernorm.weight\", \"model.layers.11.post_attention_layernorm.weight\", \"model.layers.12.self_attn.q_proj.weight\", \"model.layers.12.self_attn.k_proj.weight\", \"model.layers.12.self_attn.v_proj.weight\", \"model.layers.12.self_attn.o_proj.weight\", \"model.layers.12.mlp.gate_proj.weight\", \"model.layers.12.mlp.up_proj.weight\", \"model.layers.12.mlp.down_proj.weight\", \"model.layers.12.input_layernorm.weight\", \"model.layers.12.post_attention_layernorm.weight\", \"model.layers.13.self_attn.q_proj.weight\", \"model.layers.13.self_attn.k_proj.weight\", \"model.layers.13.self_attn.v_proj.weight\", \"model.layers.13.self_attn.o_proj.weight\", \"model.layers.13.mlp.gate_proj.weight\", \"model.layers.13.mlp.up_proj.weight\", \"model.layers.13.mlp.down_proj.weight\", \"model.layers.13.input_layernorm.weight\", \"model.layers.13.post_attention_layernorm.weight\", \"model.layers.14.self_attn.q_proj.weight\", \"model.layers.14.self_attn.k_proj.weight\", \"model.layers.14.self_attn.v_proj.weight\", \"model.layers.14.self_attn.o_proj.weight\", \"model.layers.14.mlp.gate_proj.weight\", \"model.layers.14.mlp.up_proj.weight\", \"model.layers.14.mlp.down_proj.weight\", \"model.layers.14.input_layernorm.weight\", \"model.layers.14.post_attention_layernorm.weight\", \"model.layers.15.self_attn.q_proj.weight\", \"model.layers.15.self_attn.k_proj.weight\", \"model.layers.15.self_attn.v_proj.weight\", \"model.layers.15.self_attn.o_proj.weight\", \"model.layers.15.mlp.gate_proj.weight\", \"model.layers.15.mlp.up_proj.weight\", \"model.layers.15.mlp.down_proj.weight\", \"model.layers.15.input_layernorm.weight\", \"model.layers.15.post_attention_layernorm.weight\", \"model.layers.16.self_attn.q_proj.weight\", \"model.layers.16.self_attn.k_proj.weight\", \"model.layers.16.self_attn.v_proj.weight\", \"model.layers.16.self_attn.o_proj.weight\", \"model.layers.16.mlp.gate_proj.weight\", \"model.layers.16.mlp.up_proj.weight\", \"model.layers.16.mlp.down_proj.weight\", \"model.layers.16.input_layernorm.weight\", \"model.layers.16.post_attention_layernorm.weight\", \"model.layers.17.self_attn.q_proj.weight\", \"model.layers.17.self_attn.k_proj.weight\", \"model.layers.17.self_attn.v_proj.weight\", \"model.layers.17.self_attn.o_proj.weight\", \"model.layers.17.mlp.gate_proj.weight\", \"model.layers.17.mlp.up_proj.weight\", \"model.layers.17.mlp.down_proj.weight\", \"model.layers.17.input_layernorm.weight\", \"model.layers.17.post_attention_layernorm.weight\", \"model.layers.18.self_attn.q_proj.weight\", \"model.layers.18.self_attn.k_proj.weight\", \"model.layers.18.self_attn.v_proj.weight\", \"model.layers.18.self_attn.o_proj.weight\", \"model.layers.18.mlp.gate_proj.weight\", \"model.layers.18.mlp.up_proj.weight\", \"model.layers.18.mlp.down_proj.weight\", \"model.layers.18.input_layernorm.weight\", \"model.layers.18.post_attention_layernorm.weight\", \"model.layers.19.self_attn.q_proj.weight\", \"model.layers.19.self_attn.k_proj.weight\", \"model.layers.19.self_attn.v_proj.weight\", \"model.layers.19.self_attn.o_proj.weight\", \"model.layers.19.mlp.gate_proj.weight\", \"model.layers.19.mlp.up_proj.weight\", \"model.layers.19.mlp.down_proj.weight\", \"model.layers.19.input_layernorm.weight\", \"model.layers.19.post_attention_layernorm.weight\", \"model.layers.20.self_attn.q_proj.weight\", \"model.layers.20.self_attn.k_proj.weight\", \"model.layers.20.self_attn.v_proj.weight\", \"model.layers.20.self_attn.o_proj.weight\", \"model.layers.20.mlp.gate_proj.weight\", \"model.layers.20.mlp.up_proj.weight\", \"model.layers.20.mlp.down_proj.weight\", \"model.layers.20.input_layernorm.weight\", \"model.layers.20.post_attention_layernorm.weight\", \"model.layers.21.self_attn.q_proj.weight\", \"model.layers.21.self_attn.k_proj.weight\", \"model.layers.21.self_attn.v_proj.weight\", \"model.layers.21.self_attn.o_proj.weight\", \"model.layers.21.mlp.gate_proj.weight\", \"model.layers.21.mlp.up_proj.weight\", \"model.layers.21.mlp.down_proj.weight\", \"model.layers.21.input_layernorm.weight\", \"model.layers.21.post_attention_layernorm.weight\", \"model.layers.22.self_attn.q_proj.weight\", \"model.layers.22.self_attn.k_proj.weight\", \"model.layers.22.self_attn.v_proj.weight\", \"model.layers.22.self_attn.o_proj.weight\", \"model.layers.22.mlp.gate_proj.weight\", \"model.layers.22.mlp.up_proj.weight\", \"model.layers.22.mlp.down_proj.weight\", \"model.layers.22.input_layernorm.weight\", \"model.layers.22.post_attention_layernorm.weight\", \"model.layers.23.self_attn.q_proj.weight\", \"model.layers.23.self_attn.k_proj.weight\", \"model.layers.23.self_attn.v_proj.weight\", \"model.layers.23.self_attn.o_proj.weight\", \"model.layers.23.mlp.gate_proj.weight\", \"model.layers.23.mlp.up_proj.weight\", \"model.layers.23.mlp.down_proj.weight\", \"model.layers.23.input_layernorm.weight\", \"model.layers.23.post_attention_layernorm.weight\", \"model.layers.24.self_attn.q_proj.weight\", \"model.layers.24.self_attn.k_proj.weight\", \"model.layers.24.self_attn.v_proj.weight\", \"model.layers.24.self_attn.o_proj.weight\", \"model.layers.24.mlp.gate_proj.weight\", \"model.layers.24.mlp.up_proj.weight\", \"model.layers.24.mlp.down_proj.weight\", \"model.layers.24.input_layernorm.weight\", \"model.layers.24.post_attention_layernorm.weight\", \"model.layers.25.self_attn.q_proj.weight\", \"model.layers.25.self_attn.k_proj.weight\", \"model.layers.25.self_attn.v_proj.weight\", \"model.layers.25.self_attn.o_proj.weight\", \"model.layers.25.mlp.gate_proj.weight\", \"model.layers.25.mlp.up_proj.weight\", \"model.layers.25.mlp.down_proj.weight\", \"model.layers.25.input_layernorm.weight\", \"model.layers.25.post_attention_layernorm.weight\", \"model.layers.26.self_attn.q_proj.weight\", \"model.layers.26.self_attn.k_proj.weight\", \"model.layers.26.self_attn.v_proj.weight\", \"model.layers.26.self_attn.o_proj.weight\", \"model.layers.26.mlp.gate_proj.weight\", \"model.layers.26.mlp.up_proj.weight\", \"model.layers.26.mlp.down_proj.weight\", \"model.layers.26.input_layernorm.weight\", \"model.layers.26.post_attention_layernorm.weight\", \"model.layers.27.self_attn.q_proj.weight\", \"model.layers.27.self_attn.k_proj.weight\", \"model.layers.27.self_attn.v_proj.weight\", \"model.layers.27.self_attn.o_proj.weight\", \"model.layers.27.mlp.gate_proj.weight\", \"model.layers.27.mlp.up_proj.weight\", \"model.layers.27.mlp.down_proj.weight\", \"model.layers.27.input_layernorm.weight\", \"model.layers.27.post_attention_layernorm.weight\", \"model.layers.28.self_attn.q_proj.weight\", \"model.layers.28.self_attn.k_proj.weight\", \"model.layers.28.self_attn.v_proj.weight\", \"model.layers.28.self_attn.o_proj.weight\", \"model.layers.28.mlp.gate_proj.weight\", \"model.layers.28.mlp.up_proj.weight\", \"model.layers.28.mlp.down_proj.weight\", \"model.layers.28.input_layernorm.weight\", \"model.layers.28.post_attention_layernorm.weight\", \"model.layers.29.self_attn.q_proj.weight\", \"model.layers.29.self_attn.k_proj.weight\", \"model.layers.29.self_attn.v_proj.weight\", \"model.layers.29.self_attn.o_proj.weight\", \"model.layers.29.mlp.gate_proj.weight\", \"model.layers.29.mlp.up_proj.weight\", \"model.layers.29.mlp.down_proj.weight\", \"model.layers.29.input_layernorm.weight\", \"model.layers.29.post_attention_layernorm.weight\", \"model.layers.30.self_attn.q_proj.weight\", \"model.layers.30.self_attn.k_proj.weight\", \"model.layers.30.self_attn.v_proj.weight\", \"model.layers.30.self_attn.o_proj.weight\", \"model.layers.30.mlp.gate_proj.weight\", \"model.layers.30.mlp.up_proj.weight\", \"model.layers.30.mlp.down_proj.weight\", \"model.layers.30.input_layernorm.weight\", \"model.layers.30.post_attention_layernorm.weight\", \"model.layers.31.self_attn.q_proj.weight\", \"model.layers.31.self_attn.k_proj.weight\", \"model.layers.31.self_attn.v_proj.weight\", \"model.layers.31.self_attn.o_proj.weight\", \"model.layers.31.mlp.gate_proj.weight\", \"model.layers.31.mlp.up_proj.weight\", \"model.layers.31.mlp.down_proj.weight\", \"model.layers.31.input_layernorm.weight\", \"model.layers.31.post_attention_layernorm.weight\", \"model.norm.weight\", \"lm_head.weight\". \n\tUnexpected key(s) in state_dict: \"base_model.model.model.layers.0.self_attn.q_proj.lora_A.default.weight\", \"base_model.model.model.layers.0.self_attn.q_proj.lora_B.default.weight\", \"base_model.model.model.layers.0.self_attn.v_proj.lora_A.default.weight\", \"base_model.model.model.layers.0.self_attn.v_proj.lora_B.default.weight\", \"base_model.model.model.layers.1.self_attn.q_proj.lora_A.default.weight\", \"base_model.model.model.layers.1.self_attn.q_proj.lora_B.default.weight\", \"base_model.model.model.layers.1.self_attn.v_proj.lora_A.default.weight\", \"base_model.model.model.layers.1.self_attn.v_proj.lora_B.default.weight\", \"base_model.model.model.layers.2.self_attn.q_proj.lora_A.default.weight\", \"base_model.model.model.layers.2.self_attn.q_proj.lora_B.default.weight\", \"base_model.model.model.layers.2.self_attn.v_proj.lora_A.default.weight\", \"base_model.model.model.layers.2.self_attn.v_proj.lora_B.default.weight\", \"base_model.model.model.layers.3.self_attn.q_proj.lora_A.default.weight\", \"base_model.model.model.layers.3.self_attn.q_proj.lora_B.default.weight\", \"base_model.model.model.layers.3.self_attn.v_proj.lora_A.default.weight\", \"base_model.model.model.layers.3.self_attn.v_proj.lora_B.default.weight\", \"base_model.model.model.layers.4.self_attn.q_proj.lora_A.default.weight\", \"base_model.model.model.layers.4.self_attn.q_proj.lora_B.default.weight\", \"base_model.model.model.layers.4.self_attn.v_proj.lora_A.default.weight\", \"base_model.model.model.layers.4.self_attn.v_proj.lora_B.default.weight\", \"base_model.model.model.layers.5.self_attn.q_proj.lora_A.default.weight\", \"base_model.model.model.layers.5.self_attn.q_proj.lora_B.default.weight\", \"base_model.model.model.layers.5.self_attn.v_proj.lora_A.default.weight\", \"base_model.model.model.layers.5.self_attn.v_proj.lora_B.default.weight\", \"base_model.model.model.layers.6.self_attn.q_proj.lora_A.default.weight\", \"base_model.model.model.layers.6.self_attn.q_proj.lora_B.default.weight\", \"base_model.model.model.layers.6.self_attn.v_proj.lora_A.default.weight\", \"base_model.model.model.layers.6.self_attn.v_proj.lora_B.default.weight\", \"base_model.model.model.layers.7.self_attn.q_proj.lora_A.default.weight\", \"base_model.model.model.layers.7.self_attn.q_proj.lora_B.default.weight\", \"base_model.model.model.layers.7.self_attn.v_proj.lora_A.default.weight\", \"base_model.model.model.layers.7.self_attn.v_proj.lora_B.default.weight\", \"base_model.model.model.layers.8.self_attn.q_proj.lora_A.default.weight\", \"base_model.model.model.layers.8.self_attn.q_proj.lora_B.default.weight\", \"base_model.model.model.layers.8.self_attn.v_proj.lora_A.default.weight\", \"base_model.model.model.layers.8.self_attn.v_proj.lora_B.default.weight\", \"base_model.model.model.layers.9.self_attn.q_proj.lora_A.default.weight\", \"base_model.model.model.layers.9.self_attn.q_proj.lora_B.default.weight\", \"base_model.model.model.layers.9.self_attn.v_proj.lora_A.default.weight\", \"base_model.model.model.layers.9.self_attn.v_proj.lora_B.default.weight\", \"base_model.model.model.layers.10.self_attn.q_proj.lora_A.default.weight\", \"base_model.model.model.layers.10.self_attn.q_proj.lora_B.default.weight\", \"base_model.model.model.layers.10.self_attn.v_proj.lora_A.default.weight\", \"base_model.model.model.layers.10.self_attn.v_proj.lora_B.default.weight\", \"base_model.model.model.layers.11.self_attn.q_proj.lora_A.default.weight\", \"base_model.model.model.layers.11.self_attn.q_proj.lora_B.default.weight\", \"base_model.model.model.layers.11.self_attn.v_proj.lora_A.default.weight\", \"base_model.model.model.layers.11.self_attn.v_proj.lora_B.default.weight\", \"base_model.model.model.layers.12.self_attn.q_proj.lora_A.default.weight\", \"base_model.model.model.layers.12.self_attn.q_proj.lora_B.default.weight\", \"base_model.model.model.layers.12.self_attn.v_proj.lora_A.default.weight\", \"base_model.model.model.layers.12.self_attn.v_proj.lora_B.default.weight\", \"base_model.model.model.layers.13.self_attn.q_proj.lora_A.default.weight\", \"base_model.model.model.layers.13.self_attn.q_proj.lora_B.default.weight\", \"base_model.model.model.layers.13.self_attn.v_proj.lora_A.default.weight\", \"base_model.model.model.layers.13.self_attn.v_proj.lora_B.default.weight\", \"base_model.model.model.layers.14.self_attn.q_proj.lora_A.default.weight\", \"base_model.model.model.layers.14.self_attn.q_proj.lora_B.default.weight\", \"base_model.model.model.layers.14.self_attn.v_proj.lora_A.default.weight\", \"base_model.model.model.layers.14.self_attn.v_proj.lora_B.default.weight\", \"base_model.model.model.layers.15.self_attn.q_proj.lora_A.default.weight\", \"base_model.model.model.layers.15.self_attn.q_proj.lora_B.default.weight\", \"base_model.model.model.layers.15.self_attn.v_proj.lora_A.default.weight\", \"base_model.model.model.layers.15.self_attn.v_proj.lora_B.default.weight\", \"base_model.model.model.layers.16.self_attn.q_proj.lora_A.default.weight\", \"base_model.model.model.layers.16.self_attn.q_proj.lora_B.default.weight\", \"base_model.model.model.layers.16.self_attn.v_proj.lora_A.default.weight\", \"base_model.model.model.layers.16.self_attn.v_proj.lora_B.default.weight\", \"base_model.model.model.layers.17.self_attn.q_proj.lora_A.default.weight\", \"base_model.model.model.layers.17.self_attn.q_proj.lora_B.default.weight\", \"base_model.model.model.layers.17.self_attn.v_proj.lora_A.default.weight\", \"base_model.model.model.layers.17.self_attn.v_proj.lora_B.default.weight\", \"base_model.model.model.layers.18.self_attn.q_proj.lora_A.default.weight\", \"base_model.model.model.layers.18.self_attn.q_proj.lora_B.default.weight\", \"base_model.model.model.layers.18.self_attn.v_proj.lora_A.default.weight\", \"base_model.model.model.layers.18.self_attn.v_proj.lora_B.default.weight\", \"base_model.model.model.layers.19.self_attn.q_proj.lora_A.default.weight\", \"base_model.model.model.layers.19.self_attn.q_proj.lora_B.default.weight\", \"base_model.model.model.layers.19.self_attn.v_proj.lora_A.default.weight\", \"base_model.model.model.layers.19.self_attn.v_proj.lora_B.default.weight\", \"base_model.model.model.layers.20.self_attn.q_proj.lora_A.default.weight\", \"base_model.model.model.layers.20.self_attn.q_proj.lora_B.default.weight\", \"base_model.model.model.layers.20.self_attn.v_proj.lora_A.default.weight\", \"base_model.model.model.layers.20.self_attn.v_proj.lora_B.default.weight\", \"base_model.model.model.layers.21.self_attn.q_proj.lora_A.default.weight\", \"base_model.model.model.layers.21.self_attn.q_proj.lora_B.default.weight\", \"base_model.model.model.layers.21.self_attn.v_proj.lora_A.default.weight\", \"base_model.model.model.layers.21.self_attn.v_proj.lora_B.default.weight\", \"base_model.model.model.layers.22.self_attn.q_proj.lora_A.default.weight\", \"base_model.model.model.layers.22.self_attn.q_proj.lora_B.default.weight\", \"base_model.model.model.layers.22.self_attn.v_proj.lora_A.default.weight\", \"base_model.model.model.layers.22.self_attn.v_proj.lora_B.default.weight\", \"base_model.model.model.layers.23.self_attn.q_proj.lora_A.default.weight\", \"base_model.model.model.layers.23.self_attn.q_proj.lora_B.default.weight\", \"base_model.model.model.layers.23.self_attn.v_proj.lora_A.default.weight\", \"base_model.model.model.layers.23.self_attn.v_proj.lora_B.default.weight\", \"base_model.model.model.layers.24.self_attn.q_proj.lora_A.default.weight\", \"base_model.model.model.layers.24.self_attn.q_proj.lora_B.default.weight\", \"base_model.model.model.layers.24.self_attn.v_proj.lora_A.default.weight\", \"base_model.model.model.layers.24.self_attn.v_proj.lora_B.default.weight\", \"base_model.model.model.layers.25.self_attn.q_proj.lora_A.default.weight\", \"base_model.model.model.layers.25.self_attn.q_proj.lora_B.default.weight\", \"base_model.model.model.layers.25.self_attn.v_proj.lora_A.default.weight\", \"base_model.model.model.layers.25.self_attn.v_proj.lora_B.default.weight\", \"base_model.model.model.layers.26.self_attn.q_proj.lora_A.default.weight\", \"base_model.model.model.layers.26.self_attn.q_proj.lora_B.default.weight\", \"base_model.model.model.layers.26.self_attn.v_proj.lora_A.default.weight\", \"base_model.model.model.layers.26.self_attn.v_proj.lora_B.default.weight\", \"base_model.model.model.layers.27.self_attn.q_proj.lora_A.default.weight\", \"base_model.model.model.layers.27.self_attn.q_proj.lora_B.default.weight\", \"base_model.model.model.layers.27.self_attn.v_proj.lora_A.default.weight\", \"base_model.model.model.layers.27.self_attn.v_proj.lora_B.default.weight\", \"base_model.model.model.layers.28.self_attn.q_proj.lora_A.default.weight\", \"base_model.model.model.layers.28.self_attn.q_proj.lora_B.default.weight\", \"base_model.model.model.layers.28.self_attn.v_proj.lora_A.default.weight\", \"base_model.model.model.layers.28.self_attn.v_proj.lora_B.default.weight\", \"base_model.model.model.layers.29.self_attn.q_proj.lora_A.default.weight\", \"base_model.model.model.layers.29.self_attn.q_proj.lora_B.default.weight\", \"base_model.model.model.layers.29.self_attn.v_proj.lora_A.default.weight\", \"base_model.model.model.layers.29.self_attn.v_proj.lora_B.default.weight\", \"base_model.model.model.layers.30.self_attn.q_proj.lora_A.default.weight\", \"base_model.model.model.layers.30.self_attn.q_proj.lora_B.default.weight\", \"base_model.model.model.layers.30.self_attn.v_proj.lora_A.default.weight\", \"base_model.model.model.layers.30.self_attn.v_proj.lora_B.default.weight\", \"base_model.model.model.layers.31.self_attn.q_proj.lora_A.default.weight\", \"base_model.model.model.layers.31.self_attn.q_proj.lora_B.default.weight\", \"base_model.model.model.layers.31.self_attn.v_proj.lora_A.default.weight\", \"base_model.model.model.layers.31.self_attn.v_proj.lora_B.default.weight\". "
     ]
    }
   ],
   "source": [
    "model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    config = LoraConfig(\n",
    "    r=rank, #attention heads, rank of the attention matrix, i think\n",
    "    lora_alpha= lora_alpha, #alpha scaling, scaling factor for the weight matrices\n",
    "    # target_modules=[\"q_proj\", \"v_proj\"], #will be set after i know the names\n",
    "    lora_dropout=lora_dropout,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\" # set this for CLM or Seq2Seq\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PeftModel.from_pretrained(model, pathPeftModel)\n",
    "print(\"Peft Model : \", model.device)\n",
    "print(f\"Running merge_and_unload\")\n",
    "model = model.merge_and_unload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-07-05 01:43:00,119] [INFO] [comm.py:637:init_distributed] cdb=None\n",
      "[2024-07-05 01:43:00,119] [INFO] [comm.py:652:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...\n",
      "[2024-07-05 01:43:00,195] [INFO] [comm.py:702:mpi_discovery] Discovered MPI settings of world_rank=0, local_rank=0, world_size=1, master_addr=10.1.4.1, master_port=29500\n",
      "[2024-07-05 01:43:00,195] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl\n"
     ]
    }
   ],
   "source": [
    "deepspeed.init_distributed(dist_backend=\"nccl\", world_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-07-05 01:50:34,460] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed info: version=0.14.2, git-hash=unknown, git-branch=unknown\n",
      "[2024-07-05 01:50:34,462] [INFO] [logging.py:96:log_dist] [Rank 0] quantize_bits = 8 mlp_extra_grouping = False, quantize_groups = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You shouldn't move a model when it is dispatched on multiple devices.\n"
     ]
    }
   ],
   "source": [
    "# Initialize the DeepSpeed-Inference engine\n",
    "ds_engine = deepspeed.init_inference(model,\n",
    "                                 tensor_parallel={\"tp_size\": 1},\n",
    "                                 dtype=torch.half,\n",
    "\n",
    "                                 replace_with_kernel_inject=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[    1, 36512, 28725, 32008, 23402,  3636,  2099]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = tokenizer(\"hei, jeg heter terje\", max_length=20, return_tensors='pt')\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "transformers.models.mistral.modeling_mistral.MistralForCausalLM"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('model.embed_tokens', 0),\n",
       "             ('model.layers.0', 0),\n",
       "             ('model.layers.1', 0),\n",
       "             ('model.layers.2', 0),\n",
       "             ('model.layers.3', 0),\n",
       "             ('model.layers.4', 0),\n",
       "             ('model.layers.5', 0),\n",
       "             ('model.layers.6', 0),\n",
       "             ('model.layers.7', 0),\n",
       "             ('model.layers.8', 0),\n",
       "             ('model.layers.9', 0),\n",
       "             ('model.layers.10', 0),\n",
       "             ('model.layers.11', 0),\n",
       "             ('model.layers.12', 0),\n",
       "             ('model.layers.13', 0),\n",
       "             ('model.layers.14', 0),\n",
       "             ('model.layers.15', 0),\n",
       "             ('model.layers.16', 1),\n",
       "             ('model.layers.17', 1),\n",
       "             ('model.layers.18', 1),\n",
       "             ('model.layers.19', 1),\n",
       "             ('model.layers.20', 1),\n",
       "             ('model.layers.21', 1),\n",
       "             ('model.layers.22', 1),\n",
       "             ('model.layers.23', 1),\n",
       "             ('model.layers.24', 1),\n",
       "             ('model.layers.25', 1),\n",
       "             ('model.layers.26', 1),\n",
       "             ('model.layers.27', 1),\n",
       "             ('model.layers.28', 1),\n",
       "             ('model.layers.29', 1),\n",
       "             ('model.layers.30', 1),\n",
       "             ('model.layers.31', 1),\n",
       "             ('model.norm', 1),\n",
       "             ('lm_head', 1)])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.hf_device_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cuda:1!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[40], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model\u001b[38;5;241m.\u001b[39mgenerate(input_ids\u001b[38;5;241m=\u001b[39mtokens[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda:0\u001b[39m\u001b[38;5;124m\"\u001b[39m), attention_mask\u001b[38;5;241m=\u001b[39mtokens[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda:0\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhei\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.conda/envs/vgdebatt/lib/python3.11/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/.conda/envs/vgdebatt/lib/python3.11/site-packages/transformers/generation/utils.py:1758\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   1750\u001b[0m     input_ids, model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand_inputs_for_generation(\n\u001b[1;32m   1751\u001b[0m         input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m   1752\u001b[0m         expand_size\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_return_sequences,\n\u001b[1;32m   1753\u001b[0m         is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[1;32m   1754\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[1;32m   1755\u001b[0m     )\n\u001b[1;32m   1757\u001b[0m     \u001b[38;5;66;03m# 13. run sample (it degenerates to greedy search when `generation_config.do_sample=False`)\u001b[39;00m\n\u001b[0;32m-> 1758\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sample(\n\u001b[1;32m   1759\u001b[0m         input_ids,\n\u001b[1;32m   1760\u001b[0m         logits_processor\u001b[38;5;241m=\u001b[39mprepared_logits_processor,\n\u001b[1;32m   1761\u001b[0m         logits_warper\u001b[38;5;241m=\u001b[39mprepared_logits_warper,\n\u001b[1;32m   1762\u001b[0m         stopping_criteria\u001b[38;5;241m=\u001b[39mprepared_stopping_criteria,\n\u001b[1;32m   1763\u001b[0m         generation_config\u001b[38;5;241m=\u001b[39mgeneration_config,\n\u001b[1;32m   1764\u001b[0m         synced_gpus\u001b[38;5;241m=\u001b[39msynced_gpus,\n\u001b[1;32m   1765\u001b[0m         streamer\u001b[38;5;241m=\u001b[39mstreamer,\n\u001b[1;32m   1766\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[1;32m   1767\u001b[0m     )\n\u001b[1;32m   1769\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;129;01min\u001b[39;00m (GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SAMPLE, GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SEARCH):\n\u001b[1;32m   1770\u001b[0m     \u001b[38;5;66;03m# 11. prepare logits warper\u001b[39;00m\n\u001b[1;32m   1771\u001b[0m     prepared_logits_warper \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1772\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_logits_warper(generation_config) \u001b[38;5;28;01mif\u001b[39;00m generation_config\u001b[38;5;241m.\u001b[39mdo_sample \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1773\u001b[0m     )\n",
      "File \u001b[0;32m~/.conda/envs/vgdebatt/lib/python3.11/site-packages/transformers/generation/utils.py:2397\u001b[0m, in \u001b[0;36mGenerationMixin._sample\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, logits_warper, **model_kwargs)\u001b[0m\n\u001b[1;32m   2394\u001b[0m model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprepare_inputs_for_generation(input_ids, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs)\n\u001b[1;32m   2396\u001b[0m \u001b[38;5;66;03m# forward pass to get next token\u001b[39;00m\n\u001b[0;32m-> 2397\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m(\n\u001b[1;32m   2398\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_inputs,\n\u001b[1;32m   2399\u001b[0m     return_dict\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m   2400\u001b[0m     output_attentions\u001b[38;5;241m=\u001b[39moutput_attentions,\n\u001b[1;32m   2401\u001b[0m     output_hidden_states\u001b[38;5;241m=\u001b[39moutput_hidden_states,\n\u001b[1;32m   2402\u001b[0m )\n\u001b[1;32m   2404\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m synced_gpus \u001b[38;5;129;01mand\u001b[39;00m this_peer_finished:\n\u001b[1;32m   2405\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m  \u001b[38;5;66;03m# don't waste resources running the code we don't need\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/vgdebatt/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/.conda/envs/vgdebatt/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/vgdebatt/lib/python3.11/site-packages/accelerate/hooks.py:165\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    163\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 165\u001b[0m     output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m~/.conda/envs/vgdebatt/lib/python3.11/site-packages/transformers/models/mistral/modeling_mistral.py:1139\u001b[0m, in \u001b[0;36mMistralForCausalLM.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1136\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[1;32m   1138\u001b[0m \u001b[38;5;66;03m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001b[39;00m\n\u001b[0;32m-> 1139\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel(\n\u001b[1;32m   1140\u001b[0m     input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m   1141\u001b[0m     attention_mask\u001b[38;5;241m=\u001b[39mattention_mask,\n\u001b[1;32m   1142\u001b[0m     position_ids\u001b[38;5;241m=\u001b[39mposition_ids,\n\u001b[1;32m   1143\u001b[0m     past_key_values\u001b[38;5;241m=\u001b[39mpast_key_values,\n\u001b[1;32m   1144\u001b[0m     inputs_embeds\u001b[38;5;241m=\u001b[39minputs_embeds,\n\u001b[1;32m   1145\u001b[0m     use_cache\u001b[38;5;241m=\u001b[39muse_cache,\n\u001b[1;32m   1146\u001b[0m     output_attentions\u001b[38;5;241m=\u001b[39moutput_attentions,\n\u001b[1;32m   1147\u001b[0m     output_hidden_states\u001b[38;5;241m=\u001b[39moutput_hidden_states,\n\u001b[1;32m   1148\u001b[0m     return_dict\u001b[38;5;241m=\u001b[39mreturn_dict,\n\u001b[1;32m   1149\u001b[0m )\n\u001b[1;32m   1151\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1152\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlm_head(hidden_states)\n",
      "File \u001b[0;32m~/.conda/envs/vgdebatt/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/.conda/envs/vgdebatt/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/vgdebatt/lib/python3.11/site-packages/transformers/models/mistral/modeling_mistral.py:1024\u001b[0m, in \u001b[0;36mMistralModel.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1014\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m   1015\u001b[0m         decoder_layer\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[1;32m   1016\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1021\u001b[0m         use_cache,\n\u001b[1;32m   1022\u001b[0m     )\n\u001b[1;32m   1023\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1024\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m decoder_layer(\n\u001b[1;32m   1025\u001b[0m         hidden_states,\n\u001b[1;32m   1026\u001b[0m         attention_mask\u001b[38;5;241m=\u001b[39mattention_mask,\n\u001b[1;32m   1027\u001b[0m         position_ids\u001b[38;5;241m=\u001b[39mposition_ids,\n\u001b[1;32m   1028\u001b[0m         past_key_value\u001b[38;5;241m=\u001b[39mpast_key_values,\n\u001b[1;32m   1029\u001b[0m         output_attentions\u001b[38;5;241m=\u001b[39moutput_attentions,\n\u001b[1;32m   1030\u001b[0m         use_cache\u001b[38;5;241m=\u001b[39muse_cache,\n\u001b[1;32m   1031\u001b[0m     )\n\u001b[1;32m   1033\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1035\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[0;32m~/.conda/envs/vgdebatt/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/.conda/envs/vgdebatt/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/vgdebatt/lib/python3.11/site-packages/accelerate/hooks.py:165\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    163\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 165\u001b[0m     output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m~/.conda/envs/vgdebatt/lib/python3.11/site-packages/transformers/models/mistral/modeling_mistral.py:735\u001b[0m, in \u001b[0;36mMistralDecoderLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache)\u001b[0m\n\u001b[1;32m    719\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    720\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m    721\u001b[0m \u001b[38;5;124;03m    hidden_states (`torch.FloatTensor`): input to the layer of shape `(batch, seq_len, embed_dim)`\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    730\u001b[0m \u001b[38;5;124;03m    past_key_value (`Tuple(torch.FloatTensor)`, *optional*): cached past key and value projection states\u001b[39;00m\n\u001b[1;32m    731\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    733\u001b[0m residual \u001b[38;5;241m=\u001b[39m hidden_states\n\u001b[0;32m--> 735\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_layernorm(hidden_states)\n\u001b[1;32m    737\u001b[0m \u001b[38;5;66;03m# Self Attention\u001b[39;00m\n\u001b[1;32m    738\u001b[0m hidden_states, self_attn_weights, present_key_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mself_attn(\n\u001b[1;32m    739\u001b[0m     hidden_states\u001b[38;5;241m=\u001b[39mhidden_states,\n\u001b[1;32m    740\u001b[0m     attention_mask\u001b[38;5;241m=\u001b[39mattention_mask,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    744\u001b[0m     use_cache\u001b[38;5;241m=\u001b[39muse_cache,\n\u001b[1;32m    745\u001b[0m )\n",
      "File \u001b[0;32m~/.conda/envs/vgdebatt/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/.conda/envs/vgdebatt/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/vgdebatt/lib/python3.11/site-packages/accelerate/hooks.py:165\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    163\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 165\u001b[0m     output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m~/.conda/envs/vgdebatt/lib/python3.11/site-packages/transformers/models/mistral/modeling_mistral.py:87\u001b[0m, in \u001b[0;36mMistralRMSNorm.forward\u001b[0;34m(self, hidden_states)\u001b[0m\n\u001b[1;32m     85\u001b[0m variance \u001b[38;5;241m=\u001b[39m hidden_states\u001b[38;5;241m.\u001b[39mpow(\u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39mmean(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, keepdim\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     86\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m hidden_states \u001b[38;5;241m*\u001b[39m torch\u001b[38;5;241m.\u001b[39mrsqrt(variance \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvariance_epsilon)\n\u001b[0;32m---> 87\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight \u001b[38;5;241m*\u001b[39m hidden_states\u001b[38;5;241m.\u001b[39mto(input_dtype)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cuda:1!"
     ]
    }
   ],
   "source": [
    "model.generate(input_ids=tokens['input_ids'].to(\"cuda:0\"), attention_mask=tokens['attention_mask'].to(\"cuda:0\"))\n",
    "print(\"hei\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cuda:1!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[38], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model(input_ids\u001b[38;5;241m=\u001b[39mtokens[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda:0\u001b[39m\u001b[38;5;124m\"\u001b[39m), attention_mask\u001b[38;5;241m=\u001b[39mtokens[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda:0\u001b[39m\u001b[38;5;124m\"\u001b[39m), labels\u001b[38;5;241m=\u001b[39mtokens[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda:1\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n",
      "File \u001b[0;32m~/.conda/envs/vgdebatt/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/.conda/envs/vgdebatt/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/vgdebatt/lib/python3.11/site-packages/accelerate/hooks.py:165\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    163\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 165\u001b[0m     output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m~/.conda/envs/vgdebatt/lib/python3.11/site-packages/transformers/models/mistral/modeling_mistral.py:1139\u001b[0m, in \u001b[0;36mMistralForCausalLM.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1136\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[1;32m   1138\u001b[0m \u001b[38;5;66;03m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001b[39;00m\n\u001b[0;32m-> 1139\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel(\n\u001b[1;32m   1140\u001b[0m     input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m   1141\u001b[0m     attention_mask\u001b[38;5;241m=\u001b[39mattention_mask,\n\u001b[1;32m   1142\u001b[0m     position_ids\u001b[38;5;241m=\u001b[39mposition_ids,\n\u001b[1;32m   1143\u001b[0m     past_key_values\u001b[38;5;241m=\u001b[39mpast_key_values,\n\u001b[1;32m   1144\u001b[0m     inputs_embeds\u001b[38;5;241m=\u001b[39minputs_embeds,\n\u001b[1;32m   1145\u001b[0m     use_cache\u001b[38;5;241m=\u001b[39muse_cache,\n\u001b[1;32m   1146\u001b[0m     output_attentions\u001b[38;5;241m=\u001b[39moutput_attentions,\n\u001b[1;32m   1147\u001b[0m     output_hidden_states\u001b[38;5;241m=\u001b[39moutput_hidden_states,\n\u001b[1;32m   1148\u001b[0m     return_dict\u001b[38;5;241m=\u001b[39mreturn_dict,\n\u001b[1;32m   1149\u001b[0m )\n\u001b[1;32m   1151\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1152\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlm_head(hidden_states)\n",
      "File \u001b[0;32m~/.conda/envs/vgdebatt/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/.conda/envs/vgdebatt/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/vgdebatt/lib/python3.11/site-packages/transformers/models/mistral/modeling_mistral.py:1024\u001b[0m, in \u001b[0;36mMistralModel.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1014\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m   1015\u001b[0m         decoder_layer\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[1;32m   1016\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1021\u001b[0m         use_cache,\n\u001b[1;32m   1022\u001b[0m     )\n\u001b[1;32m   1023\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1024\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m decoder_layer(\n\u001b[1;32m   1025\u001b[0m         hidden_states,\n\u001b[1;32m   1026\u001b[0m         attention_mask\u001b[38;5;241m=\u001b[39mattention_mask,\n\u001b[1;32m   1027\u001b[0m         position_ids\u001b[38;5;241m=\u001b[39mposition_ids,\n\u001b[1;32m   1028\u001b[0m         past_key_value\u001b[38;5;241m=\u001b[39mpast_key_values,\n\u001b[1;32m   1029\u001b[0m         output_attentions\u001b[38;5;241m=\u001b[39moutput_attentions,\n\u001b[1;32m   1030\u001b[0m         use_cache\u001b[38;5;241m=\u001b[39muse_cache,\n\u001b[1;32m   1031\u001b[0m     )\n\u001b[1;32m   1033\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1035\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[0;32m~/.conda/envs/vgdebatt/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/.conda/envs/vgdebatt/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/vgdebatt/lib/python3.11/site-packages/accelerate/hooks.py:165\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    163\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 165\u001b[0m     output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m~/.conda/envs/vgdebatt/lib/python3.11/site-packages/transformers/models/mistral/modeling_mistral.py:735\u001b[0m, in \u001b[0;36mMistralDecoderLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache)\u001b[0m\n\u001b[1;32m    719\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    720\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m    721\u001b[0m \u001b[38;5;124;03m    hidden_states (`torch.FloatTensor`): input to the layer of shape `(batch, seq_len, embed_dim)`\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    730\u001b[0m \u001b[38;5;124;03m    past_key_value (`Tuple(torch.FloatTensor)`, *optional*): cached past key and value projection states\u001b[39;00m\n\u001b[1;32m    731\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    733\u001b[0m residual \u001b[38;5;241m=\u001b[39m hidden_states\n\u001b[0;32m--> 735\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_layernorm(hidden_states)\n\u001b[1;32m    737\u001b[0m \u001b[38;5;66;03m# Self Attention\u001b[39;00m\n\u001b[1;32m    738\u001b[0m hidden_states, self_attn_weights, present_key_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mself_attn(\n\u001b[1;32m    739\u001b[0m     hidden_states\u001b[38;5;241m=\u001b[39mhidden_states,\n\u001b[1;32m    740\u001b[0m     attention_mask\u001b[38;5;241m=\u001b[39mattention_mask,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    744\u001b[0m     use_cache\u001b[38;5;241m=\u001b[39muse_cache,\n\u001b[1;32m    745\u001b[0m )\n",
      "File \u001b[0;32m~/.conda/envs/vgdebatt/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/.conda/envs/vgdebatt/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/vgdebatt/lib/python3.11/site-packages/accelerate/hooks.py:165\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    163\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 165\u001b[0m     output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m~/.conda/envs/vgdebatt/lib/python3.11/site-packages/transformers/models/mistral/modeling_mistral.py:87\u001b[0m, in \u001b[0;36mMistralRMSNorm.forward\u001b[0;34m(self, hidden_states)\u001b[0m\n\u001b[1;32m     85\u001b[0m variance \u001b[38;5;241m=\u001b[39m hidden_states\u001b[38;5;241m.\u001b[39mpow(\u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39mmean(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, keepdim\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     86\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m hidden_states \u001b[38;5;241m*\u001b[39m torch\u001b[38;5;241m.\u001b[39mrsqrt(variance \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvariance_epsilon)\n\u001b[0;32m---> 87\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight \u001b[38;5;241m*\u001b[39m hidden_states\u001b[38;5;241m.\u001b[39mto(input_dtype)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cuda:1!"
     ]
    }
   ],
   "source": [
    "model(input_ids=tokens['input_ids'].to(\"cuda:0\"), attention_mask=tokens['attention_mask'].to(\"cuda:0\"), labels=tokens['input_ids'].to(\"cuda:1\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cuda:1!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model(input_ids\u001b[38;5;241m=\u001b[39mtokens[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto(torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m)), attention_mask\u001b[38;5;241m=\u001b[39mtokens[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto(torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m)))\n",
      "File \u001b[0;32m~/.conda/envs/vgdebatt/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/.conda/envs/vgdebatt/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/vgdebatt/lib/python3.11/site-packages/accelerate/hooks.py:165\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    163\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 165\u001b[0m     output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m~/.conda/envs/vgdebatt/lib/python3.11/site-packages/transformers/models/mistral/modeling_mistral.py:1139\u001b[0m, in \u001b[0;36mMistralForCausalLM.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1136\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[1;32m   1138\u001b[0m \u001b[38;5;66;03m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001b[39;00m\n\u001b[0;32m-> 1139\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel(\n\u001b[1;32m   1140\u001b[0m     input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m   1141\u001b[0m     attention_mask\u001b[38;5;241m=\u001b[39mattention_mask,\n\u001b[1;32m   1142\u001b[0m     position_ids\u001b[38;5;241m=\u001b[39mposition_ids,\n\u001b[1;32m   1143\u001b[0m     past_key_values\u001b[38;5;241m=\u001b[39mpast_key_values,\n\u001b[1;32m   1144\u001b[0m     inputs_embeds\u001b[38;5;241m=\u001b[39minputs_embeds,\n\u001b[1;32m   1145\u001b[0m     use_cache\u001b[38;5;241m=\u001b[39muse_cache,\n\u001b[1;32m   1146\u001b[0m     output_attentions\u001b[38;5;241m=\u001b[39moutput_attentions,\n\u001b[1;32m   1147\u001b[0m     output_hidden_states\u001b[38;5;241m=\u001b[39moutput_hidden_states,\n\u001b[1;32m   1148\u001b[0m     return_dict\u001b[38;5;241m=\u001b[39mreturn_dict,\n\u001b[1;32m   1149\u001b[0m )\n\u001b[1;32m   1151\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1152\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlm_head(hidden_states)\n",
      "File \u001b[0;32m~/.conda/envs/vgdebatt/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/.conda/envs/vgdebatt/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/vgdebatt/lib/python3.11/site-packages/transformers/models/mistral/modeling_mistral.py:1024\u001b[0m, in \u001b[0;36mMistralModel.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1014\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m   1015\u001b[0m         decoder_layer\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[1;32m   1016\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1021\u001b[0m         use_cache,\n\u001b[1;32m   1022\u001b[0m     )\n\u001b[1;32m   1023\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1024\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m decoder_layer(\n\u001b[1;32m   1025\u001b[0m         hidden_states,\n\u001b[1;32m   1026\u001b[0m         attention_mask\u001b[38;5;241m=\u001b[39mattention_mask,\n\u001b[1;32m   1027\u001b[0m         position_ids\u001b[38;5;241m=\u001b[39mposition_ids,\n\u001b[1;32m   1028\u001b[0m         past_key_value\u001b[38;5;241m=\u001b[39mpast_key_values,\n\u001b[1;32m   1029\u001b[0m         output_attentions\u001b[38;5;241m=\u001b[39moutput_attentions,\n\u001b[1;32m   1030\u001b[0m         use_cache\u001b[38;5;241m=\u001b[39muse_cache,\n\u001b[1;32m   1031\u001b[0m     )\n\u001b[1;32m   1033\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1035\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[0;32m~/.conda/envs/vgdebatt/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/.conda/envs/vgdebatt/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/vgdebatt/lib/python3.11/site-packages/accelerate/hooks.py:165\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    163\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 165\u001b[0m     output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m~/.conda/envs/vgdebatt/lib/python3.11/site-packages/transformers/models/mistral/modeling_mistral.py:735\u001b[0m, in \u001b[0;36mMistralDecoderLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache)\u001b[0m\n\u001b[1;32m    719\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    720\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m    721\u001b[0m \u001b[38;5;124;03m    hidden_states (`torch.FloatTensor`): input to the layer of shape `(batch, seq_len, embed_dim)`\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    730\u001b[0m \u001b[38;5;124;03m    past_key_value (`Tuple(torch.FloatTensor)`, *optional*): cached past key and value projection states\u001b[39;00m\n\u001b[1;32m    731\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    733\u001b[0m residual \u001b[38;5;241m=\u001b[39m hidden_states\n\u001b[0;32m--> 735\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_layernorm(hidden_states)\n\u001b[1;32m    737\u001b[0m \u001b[38;5;66;03m# Self Attention\u001b[39;00m\n\u001b[1;32m    738\u001b[0m hidden_states, self_attn_weights, present_key_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mself_attn(\n\u001b[1;32m    739\u001b[0m     hidden_states\u001b[38;5;241m=\u001b[39mhidden_states,\n\u001b[1;32m    740\u001b[0m     attention_mask\u001b[38;5;241m=\u001b[39mattention_mask,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    744\u001b[0m     use_cache\u001b[38;5;241m=\u001b[39muse_cache,\n\u001b[1;32m    745\u001b[0m )\n",
      "File \u001b[0;32m~/.conda/envs/vgdebatt/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/.conda/envs/vgdebatt/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/vgdebatt/lib/python3.11/site-packages/accelerate/hooks.py:165\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    163\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 165\u001b[0m     output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m~/.conda/envs/vgdebatt/lib/python3.11/site-packages/transformers/models/mistral/modeling_mistral.py:87\u001b[0m, in \u001b[0;36mMistralRMSNorm.forward\u001b[0;34m(self, hidden_states)\u001b[0m\n\u001b[1;32m     85\u001b[0m variance \u001b[38;5;241m=\u001b[39m hidden_states\u001b[38;5;241m.\u001b[39mpow(\u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39mmean(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, keepdim\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     86\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m hidden_states \u001b[38;5;241m*\u001b[39m torch\u001b[38;5;241m.\u001b[39mrsqrt(variance \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvariance_epsilon)\n\u001b[0;32m---> 87\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight \u001b[38;5;241m*\u001b[39m hidden_states\u001b[38;5;241m.\u001b[39mto(input_dtype)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cuda:1!"
     ]
    }
   ],
   "source": [
    "model(input_ids=tokens['input_ids'].to(torch.device('cuda')), attention_mask=tokens['attention_mask'].to(torch.device('cuda')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "deepspeed.inference.engine.InferenceEngine"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(ds_engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "deepspeed_path = \"/cluster/home/terjenf/norwAI_All/results/Checkpoints_NRK_Peft_NorMistral/checkpoint-28000\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_engine.load_checkpoint(deepspeed_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_engine.module.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input_ids': [1, 36512, 28725, 32008, 23402, 3636, 2099], 'attention_mask': [1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "positional argument follows keyword argument (1990286007.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[10], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    model(input_ids=tokens['input_ids'], tokens['attention_mask'])\u001b[0m\n\u001b[0m                                                                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m positional argument follows keyword argument\n"
     ]
    }
   ],
   "source": [
    "model(input_ids=tokens['input_ids'], tokens['attention_mask'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<s> hei, jeg heter terje'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detokenized = tokenizer.decode(tokens['input_ids'])\n",
    "detokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/.conda/envs/vgdebatt/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:267\u001b[0m, in \u001b[0;36mBatchEncoding.__getattr__\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 267\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata[item]\n\u001b[1;32m    268\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n",
      "\u001b[0;31mKeyError\u001b[0m: 'shape'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[41], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m output \u001b[38;5;241m=\u001b[39m model(tokens)\n",
      "File \u001b[0;32m~/.conda/envs/vgdebatt/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/.conda/envs/vgdebatt/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/vgdebatt/lib/python3.11/site-packages/accelerate/hooks.py:165\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    163\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 165\u001b[0m     output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m~/.conda/envs/vgdebatt/lib/python3.11/site-packages/transformers/models/mistral/modeling_mistral.py:1139\u001b[0m, in \u001b[0;36mMistralForCausalLM.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1136\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[1;32m   1138\u001b[0m \u001b[38;5;66;03m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001b[39;00m\n\u001b[0;32m-> 1139\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel(\n\u001b[1;32m   1140\u001b[0m     input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m   1141\u001b[0m     attention_mask\u001b[38;5;241m=\u001b[39mattention_mask,\n\u001b[1;32m   1142\u001b[0m     position_ids\u001b[38;5;241m=\u001b[39mposition_ids,\n\u001b[1;32m   1143\u001b[0m     past_key_values\u001b[38;5;241m=\u001b[39mpast_key_values,\n\u001b[1;32m   1144\u001b[0m     inputs_embeds\u001b[38;5;241m=\u001b[39minputs_embeds,\n\u001b[1;32m   1145\u001b[0m     use_cache\u001b[38;5;241m=\u001b[39muse_cache,\n\u001b[1;32m   1146\u001b[0m     output_attentions\u001b[38;5;241m=\u001b[39moutput_attentions,\n\u001b[1;32m   1147\u001b[0m     output_hidden_states\u001b[38;5;241m=\u001b[39moutput_hidden_states,\n\u001b[1;32m   1148\u001b[0m     return_dict\u001b[38;5;241m=\u001b[39mreturn_dict,\n\u001b[1;32m   1149\u001b[0m )\n\u001b[1;32m   1151\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1152\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlm_head(hidden_states)\n",
      "File \u001b[0;32m~/.conda/envs/vgdebatt/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/.conda/envs/vgdebatt/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/vgdebatt/lib/python3.11/site-packages/transformers/models/mistral/modeling_mistral.py:937\u001b[0m, in \u001b[0;36mMistralModel.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    935\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou cannot specify both decoder_input_ids and decoder_inputs_embeds at the same time\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    936\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m input_ids \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 937\u001b[0m     batch_size, seq_length \u001b[38;5;241m=\u001b[39m input_ids\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m    938\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m inputs_embeds \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    939\u001b[0m     batch_size, seq_length, _ \u001b[38;5;241m=\u001b[39m inputs_embeds\u001b[38;5;241m.\u001b[39mshape\n",
      "File \u001b[0;32m~/.conda/envs/vgdebatt/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:269\u001b[0m, in \u001b[0;36mBatchEncoding.__getattr__\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m    267\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata[item]\n\u001b[1;32m    268\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[0;32m--> 269\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "output = model(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
